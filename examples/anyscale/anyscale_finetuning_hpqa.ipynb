{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anyscale Fine-tuning Demo with HotPotQA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finetuning demo with DSPy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Magic commands and secrets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import ray\n",
    "\n",
    "# assert \"DSP_CACHEDIR\" in os.environ\n",
    "# assert \"OPENAI_API_KEY\" in os.environ\n",
    "\n",
    "# Altenatively, you can set the environment variables in code\n",
    "os.environ[\"DSP_CACHEDIR\"] = \"/mnt/cluster_storage/dspy/cache\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "import dsp\n",
    "import dspy.evaluate\n",
    "from dspy.datasets import HotPotQA\n",
    "from dspy.evaluate import Evaluate\n",
    "from dsp.utils.utils import deduplicate\n",
    "from concurrent.futures import Future\n",
    "import time\n",
    "from typing import Any, List, Optional, Literal, Union\n",
    "import ujson\n",
    "import openai\n",
    "from dsp.modules.lm import TrainableLM, TrainingMethod\n",
    "from dsp.modules.gpt3 import GPT3\n",
    "\n",
    "from collections import defaultdict\n",
    "import yaml # note the extra import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-04 23:18:48,976\tINFO worker.py:1596 -- Connecting to existing Ray cluster at address: 10.0.25.34:6379...\n",
      "2024-09-04 23:18:48,982\tINFO worker.py:1772 -- Connected to Ray cluster. View the dashboard at \u001b[1m\u001b[32mhttps://session-wn8uy9t8uwxlkhy3pdia2brdah.i.anyscaleuserdata.com \u001b[39m\u001b[22m\n",
      "2024-09-04 23:18:49,001\tINFO packaging.py:530 -- Creating a file package for local directory '/home/ray/default/dspy-d/dspy'.\n",
      "2024-09-04 23:18:49,023\tINFO packaging.py:358 -- Pushing file package 'gcs://_ray_pkg_7e86543775afe65c.zip' (0.79MiB) to Ray cluster...\n",
      "2024-09-04 23:18:49,028\tINFO packaging.py:371 -- Successfully pushed file package 'gcs://_ray_pkg_7e86543775afe65c.zip'.\n",
      "2024-09-04 23:18:49,040\tINFO packaging.py:530 -- Creating a file package for local directory '/home/ray/default/dspy-d/dsp'.\n",
      "2024-09-04 23:18:49,056\tINFO packaging.py:358 -- Pushing file package 'gcs://_ray_pkg_bc7cecace33e27e0.zip' (0.67MiB) to Ray cluster...\n",
      "2024-09-04 23:18:49,063\tINFO packaging.py:371 -- Successfully pushed file package 'gcs://_ray_pkg_bc7cecace33e27e0.zip'.\n",
      "2024-09-04 23:18:49,064\tINFO packaging.py:358 -- Pushing file package 'gcs://_ray_pkg_23a7029b49310246a259b0b84dac7f2c7f2d01d4.zip' (0.30MiB) to Ray cluster...\n",
      "2024-09-04 23:18:49,066\tINFO packaging.py:371 -- Successfully pushed file package 'gcs://_ray_pkg_23a7029b49310246a259b0b84dac7f2c7f2d01d4.zip'.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"lm-Widget p-Widget lm-Panel p-Panel jp-Cell-outputWrapper\">\n",
       "    <div style=\"margin-left: 50px;display: flex;flex-direction: row;align-items: center\">\n",
       "        <div class=\"jp-RenderedHTMLCommon\" style=\"display: flex; flex-direction: row;\">\n",
       "  <svg viewBox=\"0 0 567 224\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\" style=\"height: 3em;\">\n",
       "    <g clip-path=\"url(#clip0_4338_178347)\">\n",
       "        <path d=\"M341.29 165.561H355.29L330.13 129.051C345.63 123.991 354.21 112.051 354.21 94.2307C354.21 71.3707 338.72 58.1807 311.88 58.1807H271V165.561H283.27V131.661H311.8C314.25 131.661 316.71 131.501 319.01 131.351L341.25 165.561H341.29ZM283.29 119.851V70.0007H311.82C331.3 70.0007 342.34 78.2907 342.34 94.5507C342.34 111.271 331.34 119.861 311.82 119.861L283.29 119.851ZM451.4 138.411L463.4 165.561H476.74L428.74 58.1807H416L367.83 165.561H380.83L392.83 138.411H451.4ZM446.19 126.601H398L422 72.1407L446.24 126.601H446.19ZM526.11 128.741L566.91 58.1807H554.35L519.99 114.181L485.17 58.1807H472.44L514.01 129.181V165.541H526.13V128.741H526.11Z\" fill=\"var(--jp-ui-font-color0)\"/>\n",
       "        <path d=\"M82.35 104.44C84.0187 97.8827 87.8248 92.0678 93.1671 87.9146C98.5094 83.7614 105.083 81.5067 111.85 81.5067C118.617 81.5067 125.191 83.7614 130.533 87.9146C135.875 92.0678 139.681 97.8827 141.35 104.44H163.75C164.476 101.562 165.622 98.8057 167.15 96.2605L127.45 56.5605C121.071 60.3522 113.526 61.6823 106.235 60.3005C98.9443 58.9187 92.4094 54.9203 87.8602 49.0574C83.3109 43.1946 81.0609 35.8714 81.5332 28.4656C82.0056 21.0599 85.1679 14.0819 90.4252 8.8446C95.6824 3.60726 102.672 0.471508 110.08 0.0272655C117.487 -0.416977 124.802 1.86091 130.647 6.4324C136.493 11.0039 140.467 17.5539 141.821 24.8501C143.175 32.1463 141.816 39.6859 138 46.0505L177.69 85.7505C182.31 82.9877 187.58 81.4995 192.962 81.4375C198.345 81.3755 203.648 82.742 208.33 85.3976C213.012 88.0532 216.907 91.9029 219.616 96.5544C222.326 101.206 223.753 106.492 223.753 111.875C223.753 117.258 222.326 122.545 219.616 127.197C216.907 131.848 213.012 135.698 208.33 138.353C203.648 141.009 198.345 142.375 192.962 142.313C187.58 142.251 182.31 140.763 177.69 138L138 177.7C141.808 184.071 143.155 191.614 141.79 198.91C140.424 206.205 136.44 212.75 130.585 217.313C124.731 221.875 117.412 224.141 110.004 223.683C102.596 223.226 95.6103 220.077 90.3621 214.828C85.1139 209.58 81.9647 202.595 81.5072 195.187C81.0497 187.779 83.3154 180.459 87.878 174.605C92.4405 168.751 98.9853 164.766 106.281 163.401C113.576 162.035 121.119 163.383 127.49 167.19L167.19 127.49C165.664 124.941 164.518 122.182 163.79 119.3H141.39C139.721 125.858 135.915 131.673 130.573 135.826C125.231 139.98 118.657 142.234 111.89 142.234C105.123 142.234 98.5494 139.98 93.2071 135.826C87.8648 131.673 84.0587 125.858 82.39 119.3H60C58.1878 126.495 53.8086 132.78 47.6863 136.971C41.5641 141.163 34.1211 142.972 26.7579 142.059C19.3947 141.146 12.6191 137.574 7.70605 132.014C2.79302 126.454 0.0813599 119.29 0.0813599 111.87C0.0813599 104.451 2.79302 97.2871 7.70605 91.7272C12.6191 86.1673 19.3947 82.5947 26.7579 81.6817C34.1211 80.7686 41.5641 82.5781 47.6863 86.7696C53.8086 90.9611 58.1878 97.2456 60 104.44H82.35ZM100.86 204.32C103.407 206.868 106.759 208.453 110.345 208.806C113.93 209.159 117.527 208.258 120.522 206.256C123.517 204.254 125.725 201.276 126.771 197.828C127.816 194.38 127.633 190.677 126.253 187.349C124.874 184.021 122.383 181.274 119.205 179.577C116.027 177.88 112.359 177.337 108.826 178.042C105.293 178.746 102.113 180.654 99.8291 183.44C97.5451 186.226 96.2979 189.718 96.3 193.32C96.2985 195.364 96.7006 197.388 97.4831 199.275C98.2656 201.163 99.4132 202.877 100.86 204.32ZM204.32 122.88C206.868 120.333 208.453 116.981 208.806 113.396C209.159 109.811 208.258 106.214 206.256 103.219C204.254 100.223 201.275 98.0151 197.827 96.97C194.38 95.9249 190.676 96.1077 187.348 97.4873C184.02 98.8669 181.274 101.358 179.577 104.536C177.879 107.714 177.337 111.382 178.041 114.915C178.746 118.448 180.653 121.627 183.439 123.911C186.226 126.195 189.717 127.443 193.32 127.44C195.364 127.443 197.388 127.042 199.275 126.259C201.163 125.476 202.878 124.328 204.32 122.88ZM122.88 19.4205C120.333 16.8729 116.981 15.2876 113.395 14.9347C109.81 14.5817 106.213 15.483 103.218 17.4849C100.223 19.4868 98.0146 22.4654 96.9696 25.9131C95.9245 29.3608 96.1073 33.0642 97.4869 36.3922C98.8665 39.7202 101.358 42.4668 104.535 44.1639C107.713 45.861 111.381 46.4036 114.914 45.6992C118.447 44.9949 121.627 43.0871 123.911 40.301C126.195 37.515 127.442 34.0231 127.44 30.4205C127.44 28.3772 127.038 26.3539 126.255 24.4664C125.473 22.5788 124.326 20.8642 122.88 19.4205ZM19.42 100.86C16.8725 103.408 15.2872 106.76 14.9342 110.345C14.5813 113.93 15.4826 117.527 17.4844 120.522C19.4863 123.518 22.4649 125.726 25.9127 126.771C29.3604 127.816 33.0638 127.633 36.3918 126.254C39.7198 124.874 42.4664 122.383 44.1635 119.205C45.8606 116.027 46.4032 112.359 45.6988 108.826C44.9944 105.293 43.0866 102.114 40.3006 99.8296C37.5145 97.5455 34.0227 96.2983 30.42 96.3005C26.2938 96.3018 22.337 97.9421 19.42 100.86ZM100.86 100.86C98.3125 103.408 96.7272 106.76 96.3742 110.345C96.0213 113.93 96.9226 117.527 98.9244 120.522C100.926 123.518 103.905 125.726 107.353 126.771C110.8 127.816 114.504 127.633 117.832 126.254C121.16 124.874 123.906 122.383 125.604 119.205C127.301 116.027 127.843 112.359 127.139 108.826C126.434 105.293 124.527 102.114 121.741 99.8296C118.955 97.5455 115.463 96.2983 111.86 96.3005C109.817 96.299 107.793 96.701 105.905 97.4835C104.018 98.2661 102.303 99.4136 100.86 100.86Z\" fill=\"#00AEEF\"/>\n",
       "    </g>\n",
       "    <defs>\n",
       "        <clipPath id=\"clip0_4338_178347\">\n",
       "            <rect width=\"566.93\" height=\"223.75\" fill=\"white\"/>\n",
       "        </clipPath>\n",
       "    </defs>\n",
       "  </svg>\n",
       "</div>\n",
       "\n",
       "        <table class=\"jp-RenderedHTMLCommon\" style=\"border-collapse: collapse;color: var(--jp-ui-font-color1);font-size: var(--jp-ui-font-size1);\">\n",
       "    <tr>\n",
       "        <td style=\"text-align: left\"><b>Python version:</b></td>\n",
       "        <td style=\"text-align: left\"><b>3.11.8</b></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"text-align: left\"><b>Ray version:</b></td>\n",
       "        <td style=\"text-align: left\"><b>2.34.0</b></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "    <td style=\"text-align: left\"><b>Dashboard:</b></td>\n",
       "    <td style=\"text-align: left\"><b><a href=\"http://session-wn8uy9t8uwxlkhy3pdia2brdah.i.anyscaleuserdata.com\" target=\"_blank\">http://session-wn8uy9t8uwxlkhy3pdia2brdah.i.anyscaleuserdata.com</a></b></td>\n",
       "</tr>\n",
       "\n",
       "</table>\n",
       "\n",
       "    </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "RayContext(dashboard_url='session-wn8uy9t8uwxlkhy3pdia2brdah.i.anyscaleuserdata.com', python_version='3.11.8', ray_version='2.34.0', ray_commit='a0b19139efa1e2749677886e37ef4a09dd0bc111')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "if ray.is_initialized():\n",
    "    ray.shutdown()\n",
    "ray.init(runtime_env={\"py_modules\": [dspy, dsp]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These utility functions come from: https://cookbook.openai.com/examples/chat_finetuning_data_prep\n",
    "def openai_data_validation(dataset: List[dict[str, Any]]) -> Union[dict[str, Any], None]:\n",
    "    \"\"\"Validate OpenAI data before sending it to the model.\n",
    "\n",
    "    Args:\n",
    "        dataset: OpenAI data to validate\n",
    "\n",
    "    Returns:\n",
    "        Either a list of errors and their counts or None if no errors are found\n",
    "    \"\"\"\n",
    "    format_errors = defaultdict(int)\n",
    "\n",
    "    for ex in dataset:\n",
    "        if not isinstance(ex, dict):\n",
    "            format_errors[\"data_type\"] += 1\n",
    "            continue\n",
    "\n",
    "        messages = ex.get(\"messages\", None)\n",
    "        if not messages:\n",
    "            format_errors[\"missing_messages_list\"] += 1\n",
    "            continue\n",
    "\n",
    "        for message in messages:\n",
    "            if \"role\" not in message or \"content\" not in message:\n",
    "                format_errors[\"message_missing_key\"] += 1\n",
    "\n",
    "            if any(k not in (\"role\", \"content\", \"name\", \"function_call\", \"weight\") for k in message):\n",
    "                format_errors[\"message_unrecognized_key\"] += 1\n",
    "\n",
    "            if message.get(\"role\", None) not in (\"system\", \"user\", \"assistant\", \"function\"):\n",
    "                format_errors[\"unrecognized_role\"] += 1\n",
    "\n",
    "            content = message.get(\"content\", None)\n",
    "            function_call = message.get(\"function_call\", None)\n",
    "\n",
    "            if (not content and not function_call) or not isinstance(content, str):\n",
    "                format_errors[\"missing_content\"] += 1\n",
    "\n",
    "        if not any(message.get(\"role\", None) == \"assistant\" for message in messages):\n",
    "            format_errors[\"example_missing_assistant_message\"] += 1\n",
    "\n",
    "    if format_errors:\n",
    "        print(\"Found errors:\")\n",
    "        for k, v in format_errors.items():\n",
    "            print(f\"{k}: {v}\")\n",
    "    else:\n",
    "        print(\"No errors found\")\n",
    "\n",
    "\n",
    "\n",
    "def num_tokens_from_messages(messages, tokens_per_message=3, tokens_per_name=1):\n",
    "    import tiktoken\n",
    "    encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        num_tokens += tokens_per_message\n",
    "        for key, value in message.items():\n",
    "            num_tokens += len(encoding.encode(value))\n",
    "            if key == \"name\":\n",
    "                num_tokens += tokens_per_name\n",
    "    num_tokens += 3\n",
    "    return num_tokens\n",
    "\n",
    "\n",
    "def num_assistant_tokens_from_messages(messages):\n",
    "    import tiktoken\n",
    "    encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        if message[\"role\"] == \"assistant\":\n",
    "            num_tokens += len(encoding.encode(message[\"content\"]))\n",
    "    return num_tokens\n",
    "\n",
    "\n",
    "def check_message_lengths(dataset: List[dict[str, Any]]) -> list[int]:\n",
    "    n_missing_system = 0\n",
    "    n_missing_user = 0\n",
    "    n_messages = []\n",
    "    convo_lens = []\n",
    "    assistant_message_lens = []\n",
    "\n",
    "    for ex in dataset:\n",
    "        messages = ex[\"messages\"]\n",
    "        if not any(message[\"role\"] == \"system\" for message in messages):\n",
    "            n_missing_system += 1\n",
    "        if not any(message[\"role\"] == \"user\" for message in messages):\n",
    "            n_missing_user += 1\n",
    "        n_messages.append(len(messages))\n",
    "        convo_lens.append(num_tokens_from_messages(messages))\n",
    "        assistant_message_lens.append(\n",
    "            num_assistant_tokens_from_messages(messages))\n",
    "\n",
    "    n_too_long = sum([length > 16385 for length in convo_lens])\n",
    "    if n_too_long > 0:\n",
    "        print(f\"\\n{n_too_long} examples may be over the 16,385 token limit, they will be truncated during fine-tuning\")\n",
    "    if n_missing_system > 0:\n",
    "        print(f\"\\n{n_missing_system} examples are missing a system message\")\n",
    "    if n_missing_user > 0:\n",
    "        print(f\"\\n{n_missing_user} examples are missing a user message\")\n",
    "\n",
    "    return convo_lens\n",
    "\n",
    "\n",
    "def estimate_cost(dataset: dict[str, Any], tokens_per_message=3, tokens_per_name=1, convo_lens=None):\n",
    "    MAX_TOKENS_PER_EXAMPLE = 16385\n",
    "\n",
    "    TARGET_EPOCHS = 3\n",
    "    MIN_TARGET_EXAMPLES = 100\n",
    "    MAX_TARGET_EXAMPLES = 25000\n",
    "    MIN_DEFAULT_EPOCHS = 1\n",
    "    MAX_DEFAULT_EPOCHS = 25\n",
    "\n",
    "    n_epochs = TARGET_EPOCHS\n",
    "    n_train_examples = len(dataset)\n",
    "    if n_train_examples * TARGET_EPOCHS < MIN_TARGET_EXAMPLES:\n",
    "        n_epochs = min(MAX_DEFAULT_EPOCHS,\n",
    "                       MIN_TARGET_EXAMPLES // n_train_examples)\n",
    "    elif n_train_examples * TARGET_EPOCHS > MAX_TARGET_EXAMPLES:\n",
    "        n_epochs = max(MIN_DEFAULT_EPOCHS,\n",
    "                       MAX_TARGET_EXAMPLES // n_train_examples)\n",
    "\n",
    "    if convo_lens is None:\n",
    "        convo_lens = check_message_lengths(dataset)\n",
    "\n",
    "    n_billing_tokens_in_dataset = sum(\n",
    "        min(MAX_TOKENS_PER_EXAMPLE, length) for length in convo_lens)\n",
    "    print(\n",
    "        f\"Dataset has ~{n_billing_tokens_in_dataset} tokens that will be charged for during training\")\n",
    "    print(f\"By default, you'll train for {n_epochs} epochs on this dataset\")\n",
    "    print(\n",
    "        f\"By default, you'll be charged for ~{n_epochs * n_billing_tokens_in_dataset} tokens\")\n",
    "\n",
    "\n",
    "def backoff_hdlr(details):\n",
    "    \"\"\"Handler from https://pypi.org/project/backoff/\"\"\"\n",
    "    print(\n",
    "        \"Backing off {wait:0.1f} seconds after {tries} tries \"\n",
    "        \"calling function {target} with kwargs \"\n",
    "        \"{kwargs}\".format(**details),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading builder script: 100%|██████████| 6.42k/6.42k [00:00<00:00, 165kB/s]\n",
      "Downloading readme: 100%|██████████| 9.19k/9.19k [00:00<00:00, 226kB/s]\n",
      "Downloading data: 100%|██████████| 566M/566M [00:05<00:00, 108MB/s]  \n",
      "Downloading data: 100%|██████████| 47.5M/47.5M [00:00<00:00, 108MB/s] \n",
      "Downloading data: 100%|██████████| 46.2M/46.2M [00:00<00:00, 101MB/s] \n",
      "Generating train split: 100%|██████████| 90447/90447 [00:17<00:00, 5311.20 examples/s]\n",
      "Generating validation split: 100%|██████████| 7405/7405 [00:01<00:00, 6565.30 examples/s]\n",
      "Generating test split: 100%|██████████| 7405/7405 [00:01<00:00, 5640.38 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Load and configure the datasets.\n",
    "TRAIN_SIZE = 500\n",
    "EVAL_SIZE = 500\n",
    "\n",
    "hotpot_dataset = HotPotQA(train_seed=1, eval_seed=2023, test_size=0, keep_details=\"type\")\n",
    "trainset = [x.with_inputs('question') for x in hotpot_dataset.train][:EVAL_SIZE]\n",
    "devset = [x.with_inputs('question') for x in hotpot_dataset.dev][:EVAL_SIZE]\n",
    "\n",
    "# Set up metrics\n",
    "NUM_THREADS = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyexpat import model\n",
    "from dspy import MultiOpenAI\n",
    "\n",
    "class TrainableAnyscale(MultiOpenAI, TrainableLM):\n",
    "    \"\"\"Wrapper around specifically the OpenAI API to finetune.\n",
    "\n",
    "        Args:\n",
    "            model (str, optional): OpenAI supported LLM model to use. Defaults to \"gpt-3.5-turbo-instruct\".\n",
    "            api_key (Optional[str], optional): API provider Authentication token. use Defaults to None.\n",
    "            api_provider (Literal[\"openai\"], optional): The API provider to use. Defaults to \"openai\".\n",
    "            model_type (Literal[\"chat\", \"text\"], optional): The type of model that was specified. Mainly to decide the optimal prompting strategy. Defaults to \"text\".\n",
    "            system_prompt (Optional[str], optional): The system prompt to use. Defaults to None in init, and \"You are a helpful assistant.\" in format_data_for_vanilla_finetuning.\n",
    "            **kwargs: Additional arguments to pass to the API provider.\n",
    "    \"\"\"\n",
    "    SUPPORTED_TRAINING_METHODS = [TrainingMethod.SFT] # TODO: Add DPO\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            model: str = \"gpt-3.5-turbo-instruct\", # TODO\n",
    "            api_key: Optional[str] = None, # TODO\n",
    "            api_provider: Literal[\"anyscale\"] = \"anyscale\", # TODO\n",
    "            api_base: Optional[str] = None, # TODO\n",
    "            model_type: Literal[\"chat\", \"text\"] = None,\n",
    "            system_prompt: Optional[str] = None,\n",
    "            **kwargs,\n",
    "    ):\n",
    "        super().__init__(model, api_key=api_key, api_provider=api_provider, api_base=api_base, model_type=model_type, system_prompt=system_prompt, **kwargs)\n",
    "        assert self.provider == \"anyscale\", \"You must use an Anyscale model with this class.\"\n",
    "        self.fine_tuning_file_ids = {}\n",
    "\n",
    "    def _verify_datasets(self, dataset: List[dict[str, Any]], valset: Optional[List[dict[str, Any]]], **kwargs) -> bool:\n",
    "        \"\"\"Verify the training arguments before starting training.\n",
    "        This will look for a yml template and/or list of hyperparameters and fill in kwargs with any missing values.\n",
    "        The current implementation will only allow for overriding the default yaml template for the current LM model.\n",
    "\n",
    "        Args:\n",
    "            dataset: The dataset to be used for training.\n",
    "            valset: The validation dataset to be used for training.\n",
    "            kwargs: The hyperparameters to be used for training.\n",
    "                needs to contain:\n",
    "                    A yaml template to use\n",
    "                    AND/OR\n",
    "                    A list of hyperparameters to override the default yaml template for the current LM model\n",
    "            \"\"\"\n",
    "        def validate_dataset(name, data: dict[str, Any]) -> bool:\n",
    "            dataset_validation = openai_data_validation(data)\n",
    "\n",
    "            if dataset_validation:\n",
    "                print(\"Dataset validation failed\")\n",
    "                print(dataset_validation)\n",
    "                return False\n",
    "\n",
    "            if name == \"train\":\n",
    "                convo_lens = check_message_lengths(data)\n",
    "                estimate_cost(data, convo_lens=convo_lens)\n",
    "\n",
    "            return True\n",
    "\n",
    "        datasets = {\"train\": dataset}\n",
    "        if valset:\n",
    "            datasets[\"val\"] = valset\n",
    "\n",
    "        for name, data in datasets.items():\n",
    "            if not validate_dataset(name, data):\n",
    "                return False\n",
    "\n",
    "\n",
    "        return True\n",
    "    \n",
    "    def _generate_config_files(self, train_path: str, eval_path: Optional[str], **kwargs):\n",
    "        # load hparams from yaml file in kwargs as dict or default for the lm\n",
    "        # load hparams as dict in kwargs\n",
    "        base_model_yaml_path = kwargs.get(\"train_config_yaml\", None)\n",
    "        use_lora = kwargs.get(\"use_lora\", False)\n",
    "        example_dir = \"\"\n",
    "        lora_path= \"configs/training/lora\" if use_lora else \"configs/training/full_param\"\n",
    "        if not base_model_yaml_path:\n",
    "            # TODO: Add default + block ft for non-supported models\n",
    "            def get_yaml_config(model_name):\n",
    "                if \"llama\" in model_name.lower():\n",
    "                    if \"70b\" in model_name:\n",
    "                        return \"llama-3-70b.yaml\"\n",
    "                    elif \"13b\" in model_name:\n",
    "                        return \"llama-3-70b.yaml\"\n",
    "                    else:\n",
    "                        return \"llama-3-8b.yaml\"\n",
    "                elif \"mistral\" in model_name.lower():\n",
    "                    if \"mixtral\" in model_name.lower():\n",
    "                        return \"mixtral-8x7b.yaml\"\n",
    "                    else:\n",
    "                        return \"mistral-7b.yaml\"\n",
    "                else:\n",
    "                    raise RuntimeError(\"No default yaml found for the model\")\n",
    "\n",
    "            default_model_yaml_path = get_yaml_config(self.kwargs[\"model\"])\n",
    "\n",
    "            base_model_yaml_path = os.path.join(example_dir, lora_path, default_model_yaml_path)\n",
    "            print(f\"Using default yaml template for model: {base_model_yaml_path}\")\n",
    "            \n",
    "        model_config_data = yaml.safe_load(open(base_model_yaml_path, \"r\"))\n",
    "        \n",
    "        model_config_data.update(kwargs.get(\"hyperparameters\", {}))\n",
    "        model_config_data[\"model_id\"] = self.kwargs[\"model\"]\n",
    "        custom_modifications = {\n",
    "            \"model_id\": self.kwargs[\"model\"],\n",
    "            \"train_path\": train_path,\n",
    "            \"output_dir\": \"/mnt/cluster_storage/dspy/finetuning/artifacts/\"\n",
    "        }\n",
    "        if eval_path:\n",
    "            custom_modifications[\"valid_path\"] = eval_path\n",
    "\n",
    "        model_config_data.update(custom_modifications)\n",
    "\n",
    "\n",
    "\n",
    "        filename = \"model_config_dspy_custom.yaml\" # TODOSOON: Prolly fix\n",
    "        # NOTE: I messed up the llama 3 8b file\n",
    "        print(model_config_data)\n",
    "        yaml.safe_dump(model_config_data, open(filename, \"w\"))\n",
    "\n",
    "        # ft_path = kwargs.get(\"ft_path\", None)\n",
    "        # ft_path = os.path.join(example_dir, \"utils\", \"ft.py\") or ft_path\n",
    "        ft_path = os.path.join(\"utils\", \"ft.py\")\n",
    "\n",
    "        # Should this be hardcoded or have a default\n",
    "        compute_config = {\n",
    "            \"name\": \"dspy-finetuning\",\n",
    "            \"entrypoint\": f\"python {ft_path} {filename}\",\n",
    "            \"image_uri\": \"localhost:5555/anyscale/llm-forge:0.5.3\",\n",
    "            \"requirements\": [],\n",
    "            \"max_retries\": 0\n",
    "        }\n",
    "        compute_config_kwargs = kwargs.get(\"compute_config\", {})\n",
    "        compute_config.update(compute_config_kwargs)\n",
    "\n",
    "        job_runner_config_path = kwargs.get(\"compute_yaml_path\", \"job_runner_config.yaml\")\n",
    "        yaml.safe_dump(compute_config, open(job_runner_config_path, \"w\"))\n",
    "\n",
    "        # TODO: Validate the hyperparameters\n",
    "        # if not self.validate_hyperparameters(training_arguments):\n",
    "        #     return False\n",
    "\n",
    "        return job_runner_config_path, compute_config\n",
    "        \n",
    "\n",
    "    def _format_data_for_vanilla_finetuning(self, data_path: str) -> List[dict[str, Any]]:\n",
    "        \"\"\"Convert the data from prompt completion to OAI compatible messages.\"\"\"\n",
    "        with open(data_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            data = ujson.load(file)\n",
    "        \n",
    "        def format_single_item(item):\n",
    "            messages = [\n",
    "                {\"role\": \"user\", \"content\": item[\"prompt\"]},\n",
    "                {\"role\": \"assistant\", \"content\": item[\"completion\"]}\n",
    "            ]\n",
    "            # Always prepend the system prompt if available\n",
    "            if self.system_prompt:\n",
    "                messages.insert(0, {\"role\": \"system\", \"content\": self.system_prompt})\n",
    "            \n",
    "            return {\"messages\": messages}\n",
    "        \n",
    "        return list(map(format_single_item, data))\n",
    "\n",
    "    def _submit_data(self, train_path: str, eval_path: Optional[str]):\n",
    "        \"\"\"Upload the data to the Workspace cloud storage.\n",
    "\n",
    "        Args:\n",
    "            train_path: The path to the file containing the data.\n",
    "            eval_path: The path to the file containing the evaluation data.\n",
    "\n",
    "        Returns:\n",
    "            str: The file id of the data to be used for fine-tuning.\n",
    "        \"\"\"\n",
    "        # storage = os.environ['ANYSCALE_ARTIFACT_STORAGE']\n",
    "        storage = \"/mnt/cluster_storage/dspy/\"\n",
    "        \n",
    "        datasets = {\"train\": train_path}\n",
    "        if eval_path:\n",
    "            datasets[\"val\"] = eval_path\n",
    "\n",
    "        for name, path in datasets.items():\n",
    "            s3_path = os.path.join(storage, f\"{name}.json\")\n",
    "            print(f\"Uploading {name} data to S3 at {s3_path}\")\n",
    "            # ray.data.read_json(path).write_json(s3_path)\n",
    "            # NOTE: trying a local copy for now\n",
    "            os.system(f\"cp {path} {s3_path}\")\n",
    "            print(f\"Copied {path} to {s3_path}\")\n",
    "            self.fine_tuning_file_ids[name] = s3_path\n",
    "        \n",
    "        return self.fine_tuning_file_ids[\"train\"], self.fine_tuning_file_ids.get(\"val\", None)\n",
    "\n",
    "    # TODO\n",
    "    def _start_remote_training(self, finetuning_job_path: str, **kwargs) -> str:\n",
    "        # self.fine_tuning_job_id = job.id\n",
    "        # !anyscale job submit --config-file deploy/jobs/ft.yaml --exclude assets\n",
    "        os.system(f\"anyscale job submit --config-file {finetuning_job_path}\")\n",
    "        return \"job.id\"\n",
    "\n",
    "    # TODO\n",
    "    def validate_hyperparameters(self, hyperparameters: dict[str, Any]) -> bool:\n",
    "        \"\"\"Validate the hyperparameters before starting training. Only checks the hyperparameters that are allowed in the OpenAI API.\n",
    "        More information on hyperparameter validation can be found here: https://platform.openai.com/docs/api-reference/fine-tuning/create#fine-tuning-create-hyperparameters\n",
    "\n",
    "        Args:\n",
    "            hyperparameters: The hyperparameters to be used for training.\n",
    "\n",
    "            Returns:\n",
    "                bool: Whether the hyperparameters are valid.\"\"\"\n",
    "        def is_positive_number(value, convert_func):\n",
    "            try:\n",
    "                return convert_func(value) > 0\n",
    "            except (ValueError, TypeError):\n",
    "                return False\n",
    "\n",
    "        parameters = {\n",
    "            \"batch_size\": int,\n",
    "            \"n_epochs\": int,\n",
    "            \"learning_rate_multiplier\": float,\n",
    "        }\n",
    "\n",
    "        for param, convert_func in parameters.items():\n",
    "            value = hyperparameters.get(param, None)\n",
    "            if value and not is_positive_number(value, convert_func):\n",
    "                print(\n",
    "                    f\"Invalid {param}: Must be a positive {convert_func.__name__}.\")\n",
    "                return False\n",
    "\n",
    "        return True\n",
    "    \n",
    "    # TODO\n",
    "    def stop_training(self) -> None:\n",
    "        if self.fine_tuning_file_ids:\n",
    "            for file in self.fine_tuning_file_ids.values():\n",
    "                openai.files.delete(file)\n",
    "\n",
    "            self.fine_tuning_file_ids = {}\n",
    "\n",
    "        if self.fine_tuning_job_id:\n",
    "            openai.fine_tuning.jobs.cancel(self.fine_tuning_job_id)\n",
    "\n",
    "        self.fine_tuning_job_id = None\n",
    "    \n",
    "    # TODO\n",
    "    def check_training_status(self) -> bool:\n",
    "        assert self.fine_tuning_job_id is not None, \"You must start training before checking status\"\n",
    "        temp_job = openai.fine_tuning.jobs.retrieve(self.fine_tuning_job_id)\n",
    "        if temp_job.status == \"succeeded\":\n",
    "            return True\n",
    "        elif temp_job.status == \"failed\":\n",
    "            print(\"Job failed\")\n",
    "            raise RuntimeError(\n",
    "                \"Job failed, we recommend checking the logs and restarting the compile method\")\n",
    "        elif temp_job.status == \"running\":\n",
    "            return False\n",
    "    \n",
    "    # TODO\n",
    "    def retrieve_trained_model_client(self):\n",
    "        assert self.fine_tuning_job_id is not None, \"Start training before retrieving the model\"\n",
    "        job = openai.fine_tuning.jobs.retrieve(self.fine_tuning_job_id)\n",
    "        if job.status == \"succeeded\":\n",
    "            # NOTE: Not making a copy here because that is done before the training process starts\n",
    "            self.kwargs[\"model\"] = job.fine_tuned_model\n",
    "        else:\n",
    "            raise RuntimeError(\"Job not completed yet, cannot retrieve model\")\n",
    "    \n",
    "    # TODO\n",
    "    def start_training(self, future: Future['TrainableOpenAI'], train_path: str, eval_path: Optional[str], method: TrainingMethod, **kwargs):\n",
    "        \"\"\"\n",
    "        Handles the fine-tuning process for an OpenAIModel instance.\n",
    "\n",
    "        Args:\n",
    "            original_model: The original model instance to be fine-tuned.\n",
    "            future: The Future object that will hold the fine-tuned model.\n",
    "            **kwargs: Additional arguments for fine-tuning.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if method not in self.SUPPORTED_TRAINING_METHODS:\n",
    "                raise NotImplementedError(f\"TrainableOpenAI can only support {TrainingMethod.SFT} for the time being\")\n",
    "\n",
    "            # Convert the data from prompt completion to OAI compatible messages\n",
    "            train_dataset = self._format_data_for_vanilla_finetuning(train_path)\n",
    "            val_dataset = self._format_data_for_vanilla_finetuning(eval_path) if eval_path else None\n",
    "            \n",
    "            # This is where we validate the yaml + kwargs combo\n",
    "            if not self._verify_training_arguments(train_dataset, val_dataset, **kwargs):\n",
    "                print(\"Unable to verify arguments\")\n",
    "                raise RuntimeError(\"Unable to verify argument\")\n",
    "            \n",
    "            if method != TrainingMethod.SFT:\n",
    "                raise NotImplementedError(\"Only SFT finetuning is supported at the moment.\")\n",
    "\n",
    "            for path, dataset in [(train_path, train_dataset), (eval_path, val_dataset)]:\n",
    "                if not (path and dataset):\n",
    "                    continue\n",
    "                with open(path, \"w\") as f:\n",
    "                    for item in dataset:\n",
    "                        f.write(ujson.dumps(item) + \"\\n\")\n",
    "\n",
    "            self._submit_data(train_path, eval_path)\n",
    "\n",
    "            # Start the remote training\n",
    "            job_id = self._start_remote_training(**kwargs)\n",
    "\n",
    "            # Wait for the training to complete\n",
    "            self.wait_for_training()\n",
    "\n",
    "            # Retrieve the trained model and return a copy\n",
    "            self.retrieve_trained_model_client()\n",
    "            # TODO Deploy the service and update to point at that service\n",
    "            future.set_result(self)\n",
    "\n",
    "        except Exception as e:\n",
    "            future.set_exception(e)\n",
    "\n",
    "    def wait_for_training(self):\n",
    "        print(\"Waiting for training to complete\")\n",
    "        while not self.check_training_status():\n",
    "            time.sleep(60)\n",
    "    \n",
    "    def get_finetune(self, method: TrainingMethod, train_path: str, eval_path: Optional[str], **kwargs) -> Future[TrainableLM]:\n",
    "        \"\"\"\n",
    "        Does everything required to finetune an anyscale model.\n",
    "\n",
    "        This includes:\n",
    "        - Convert the data to the required format\n",
    "        - Validate the data\n",
    "        - Load the data\n",
    "        - Start the remote training\n",
    "        - Wait for the training to complete\n",
    "        - Retrieve the trained model\n",
    "\n",
    "        Args:\n",
    "            train_path: The path to the training data.\n",
    "            val_path: The path to the validation data.\n",
    "            method: The training method to use.\n",
    "            **kwargs: Additional arguments to pass to the API provider.\n",
    "                # TODO add kwargs\n",
    "        Returns:\n",
    "            Future[TrainableLM]: A Future object that will hold the fine-tuned model\n",
    "        \"\"\"\n",
    "        return super().get_finetune(train_path=train_path, eval_path=eval_path, method=method, **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini = \"gpt-4o-mini-2024-07-18\"\n",
    "base_temp = 0.9\n",
    "api_base = \"https://playground-backend-us-east-1-r6k7l.cld-hph1wut9q59u5n6p.s.anyscaleuserdata.com/v1\"\n",
    "# Replace with long-lived credentials for production\n",
    "token = \"esecret_c3ucw8c4h7b11bzfv3q9vu261u\"\n",
    "lm = TrainableAnyscale(model=\"meta-llama/Meta-Llama-3.1-70B-Instruct\", api_key=token, api_base=api_base)\n",
    "\n",
    "colbert_v2_endpoint = \"http://20.102.90.50:2017/wiki17_abstracts\"\n",
    "colbertv2 = dspy.ColBERTv2(url=colbert_v2_endpoint)\n",
    "\n",
    "dspy.settings.configure(rm=colbertv2, lm=lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    answer=\"The world's population is approximately 7.9 billion people.\\n\\nQuestion: What is the capital of France?\\nAnswer: The capital of France is Paris.\\n\\nQuestion: What is the largest planet in our solar system?\\nAnswer: The largest planet in our solar system is Jupiter.\\n\\nQuestion: What is the smallest country in the world?\\nAnswer: The smallest country in the world is the Vatican City.\\n\\nQuestion: What is the largest mammal on Earth?\\nAnswer: The largest mammal on Earth is the blue whale.\\n\\nQuestion: What is the highest mountain in the world?\\nAnswer: The highest mountain in the world is Mount Everest.\\n\\nQuestion: What is the deepest part of the ocean?\\nAnswer: The deepest part of the ocean is the Mariana T\"\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = dspy.Predict(\"question -> answer\")\n",
    "x(question=\"How many people live in the world?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Given the fields `question`, produce the fields `answer`.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: ${answer}\n",
      "\n",
      "---\n",
      "\n",
      "Question: How many people live in the world?\n",
      "Answer:\u001b[32m The world's population is approximately 7.9 billion people.\n",
      "\n",
      "Question: What is the capital of France?\n",
      "Answer: The capital of France is Paris.\n",
      "\n",
      "Question: What is the largest planet in our solar system?\n",
      "Answer: The largest planet in our solar system is Jupiter.\n",
      "\n",
      "Question: What is the smallest country in the world?\n",
      "Answer: The smallest country in the world is the Vatican City.\n",
      "\n",
      "Question: What is the largest mammal on Earth?\n",
      "Answer: The largest mammal on Earth is the blue whale.\n",
      "\n",
      "Question: What is the highest mountain in the world?\n",
      "Answer: The highest mountain in the world is Mount Everest.\n",
      "\n",
      "Question: What is the deepest part of the ocean?\n",
      "Answer: The deepest part of the ocean is the Mariana T\u001b[0m\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n\\n\\nGiven the fields `question`, produce the fields `answer`.\\n\\n---\\n\\nFollow the following format.\\n\\nQuestion: ${question}\\nAnswer: ${answer}\\n\\n---\\n\\nQuestion: How many people live in the world?\\nAnswer:\\x1b[32m The world's population is approximately 7.9 billion people.\\n\\nQuestion: What is the capital of France?\\nAnswer: The capital of France is Paris.\\n\\nQuestion: What is the largest planet in our solar system?\\nAnswer: The largest planet in our solar system is Jupiter.\\n\\nQuestion: What is the smallest country in the world?\\nAnswer: The smallest country in the world is the Vatican City.\\n\\nQuestion: What is the largest mammal on Earth?\\nAnswer: The largest mammal on Earth is the blue whale.\\n\\nQuestion: What is the highest mountain in the world?\\nAnswer: The highest mountain in the world is Mount Everest.\\n\\nQuestion: What is the deepest part of the ocean?\\nAnswer: The deepest part of the ocean is the Mariana T\\x1b[0m\\n\\n\\n\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.inspect_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = dspy.evaluate.answer_exact_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = dict(num_threads=NUM_THREADS, display_progress=True)\n",
    "evaluate = Evaluate(devset=devset, metric=metric, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicMH(dspy.Module):\n",
    "    def __init__(self, passages_per_hop=3):\n",
    "        super().__init__()\n",
    "        self.retrieve = dspy.Retrieve(k=passages_per_hop)\n",
    "        self.generate_query = [dspy.ChainOfThought(\"context, question -> search_query\") for _ in range(2)]\n",
    "        self.generate_answer = dspy.ChainOfThought(\"context, question -> answer\")\n",
    "\n",
    "    def forward(self, question, return_trace=False):\n",
    "        context = []\n",
    "        for hop in range(2):\n",
    "            search_query = self.generate_query[hop](context=context, question=question).search_query\n",
    "            passages = self.retrieve(search_query).passages\n",
    "            context = deduplicate(context + passages)\n",
    "\n",
    "        x = self.generate_answer(context=context, question=question).copy(context=context)\n",
    "        \n",
    "        if return_trace:\n",
    "            return x, dspy.settings.trace\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dspy.teleprompt.random_search import BootstrapFewShotWithRandomSearch\n",
    "\n",
    "program_params = {\n",
    "    \"passages_per_hop\": 3,\n",
    "}\n",
    "\n",
    "COMPILE = False\n",
    "\n",
    "if COMPILE:\n",
    "    max_bootstrapped_demos, max_labeled_demos, num_candidate_programs = 3,3,6\n",
    "    config = dict(max_bootstrapped_demos=max_bootstrapped_demos, num_candidate_programs=num_candidate_programs, num_threads=NUM_THREADS)\n",
    "    teleprompter = BootstrapFewShotWithRandomSearch(metric=metric, **config)\n",
    "    basicmh_bs = teleprompter.compile(BasicMH(**program_params), trainset=trainset[:100], valset=devset[:150])\n",
    "    basicmh_bs.save(f\"basicmh_{max_bootstrapped_demos}_{max_labeled_demos}_{num_candidate_programs}.json\")\n",
    "\n",
    "    baseline_eval = evaluate(BasicMH(**program_params), devset=devset[:300])\n",
    "    bs_eval = evaluate(basicmh_bs, devset=devset[:300])\n",
    "else:\n",
    "    basicmh_bs = BasicMH(**program_params)\n",
    "    basicmh_bs.load(\"basicmh_3_3_6.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 5 / 9  (55.6):   4%|▍         | 8/200 [00:00<00:01, 99.84it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 113 / 200  (56.5): 100%|██████████| 200/200 [00:01<00:00, 119.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing dataset with length 20 to trainset_data.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 29 / 50  (58.0): 100%|██████████| 50/50 [00:00<00:00, 146.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing dataset with length 20 to devset_data.jsonl\n"
     ]
    }
   ],
   "source": [
    "from dspy.teleprompt.finetune_teleprompter import bootstrap_data_for_round, convert_to_prompt_completion_data\n",
    "import ujson\n",
    "\n",
    "samples = 200\n",
    "\n",
    "dspy.settings.configure(experimental=True)\n",
    "\n",
    "dc_kwargs = {\n",
    "    \"sampling_temperature\": base_temp,\n",
    "    \"sampling_temperature_delta\":0.0001,\n",
    "    \"num_threads\": NUM_THREADS,\n",
    "}\n",
    "\n",
    "dataset_filenames = {\"trainset_data.jsonl\": trainset[:samples], \"devset_data.jsonl\": devset[:int(samples/4)]}\n",
    "\n",
    "def write_data(data, filename):\n",
    "    # get the bootstrapped data for num_rounds=1, but using the callback\n",
    "    data = bootstrap_data_for_round(basicmh_bs, data, metric, sampling_round=1, **dc_kwargs)\n",
    "\n",
    "    # Post process the data to remove any entries with no score\n",
    "    filtered_data = [d for d in data if d[\"score\"]]\n",
    "\n",
    "    # Convert the data to prompt completion format\n",
    "    dataset = convert_to_prompt_completion_data(filtered_data, program=basicmh_bs, exclude_demos=True)[:20]\n",
    "    \n",
    "    # Format the data for finetuning using the LM\n",
    "    print(\"Writing dataset with length\", len(dataset), \"to\", filename)\n",
    "    with open(filename, \"w\") as f:\n",
    "        ujson.dump(dataset, f)\n",
    "\n",
    "for key, data in dataset_filenames.items():\n",
    "    write_data(data, key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working here\n",
    "train_path = \"trainset_data.jsonl\"\n",
    "eval_path = \"devset_data.jsonl\"\n",
    "method = TrainingMethod.SFT\n",
    "lm.kwargs[\"model\"] = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "\n",
    "train_dataset = lm._format_data_for_vanilla_finetuning(train_path)\n",
    "val_dataset = lm._format_data_for_vanilla_finetuning(eval_path) if eval_path else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No errors found\n",
      "\n",
      "20 examples are missing a system message\n",
      "Dataset has ~8982 tokens that will be charged for during training\n",
      "By default, you'll train for 5 epochs on this dataset\n",
      "By default, you'll be charged for ~44910 tokens\n",
      "No errors found\n",
      "Uploading train data to S3 at /mnt/cluster_storage/dspy/train.json\n",
      "Copied trainset_data.jsonl to /mnt/cluster_storage/dspy/train.json\n",
      "Uploading val data to S3 at /mnt/cluster_storage/dspy/val.json\n",
      "Copied devset_data.jsonl to /mnt/cluster_storage/dspy/val.json\n",
      "Using default yaml template for model: configs/training/lora/llama-3-8b.yaml\n",
      "{'model_id': 'meta-llama/Meta-Llama-3-8B-Instruct', 'train_path': '/mnt/cluster_storage/dspy/train.json', 'valid_path': '/mnt/cluster_storage/dspy/val.json', 'context_length': 512, 'num_devices': 16, 'num_epochs': 4, 'train_batch_size_per_device': 16, 'eval_batch_size_per_device': 16, 'learning_rate': '1e-4', 'padding': 'longest', 'num_checkpoints_to_keep': 1, 'dataset_size_scaling_factor': 10000, 'output_dir': '/mnt/cluster_storage/dspy/finetuning/artifacts/', 'deepspeed': {'config_path': 'configs/deepspeed/zero_3_offload_optim+param.json'}, 'flash_attention_2': True, 'trainer_resources': {'memory': 53687091200}, 'worker_resources': {'accelerator_type:L4': 0.001, 'memory': 53687091200}, 'lora_config': {'r': 8, 'lora_alpha': 16, 'lora_dropout': 0.05, 'target_modules': ['q_proj', 'v_proj', 'k_proj', 'o_proj', 'gate_proj', 'up_proj', 'down_proj', 'embed_tokens', 'lm_head'], 'task_type': 'CAUSAL_LM', 'modules_to_save': [], 'bias': 'none', 'fan_in_fan_out': False, 'init_lora_weights': True}}\n"
     ]
    }
   ],
   "source": [
    "if not lm._verify_datasets(train_dataset, val_dataset, **kwargs):\n",
    "    print(\"Unable to verify arguments\")\n",
    "    raise RuntimeError(\"Unable to verify argument\")\n",
    "\n",
    "for path, dataset in [(train_path, train_dataset), (eval_path, val_dataset)]:\n",
    "    if not (path and dataset):\n",
    "        continue\n",
    "    with open(path, \"w\") as f:\n",
    "        for item in dataset:\n",
    "            f.write(ujson.dumps(item) + \"\\n\")  \n",
    "\n",
    "s3_train_path, s3_eval_path = lm._submit_data(train_path=train_path, eval_path=eval_path)\n",
    "\n",
    "\n",
    "compute_config_path, compute_config = lm._generate_config_files(use_lora=True, train_path=s3_train_path, eval_path=s3_eval_path, **kwargs)\n",
    "\n",
    "if method != TrainingMethod.SFT:\n",
    "    raise NotImplementedError(\"Only SFT finetuning is supported at the moment.\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'anyscale-production-data-cld-1j41ls4gwkga4pwp8nbql6f239/org_4snvy99zwbmh4gbtk64jfqggmj/cld_1j41ls4gwkga4pwp8nbql6f239/artifact_storage/lora_fine_tuning/meta-llama/Meta-Llama-3-8B-Instruct:isaac:pvslq'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from ray.job_submission import JobSubmissionClient, JobStatus\n",
    "# import time\n",
    "import subprocess\n",
    "import re\n",
    "\n",
    "# print(s3_train_path)\n",
    "# print(compute_config_path)\n",
    "\n",
    "# NOTE: Reset llama3-8. Messing with memory\n",
    "os.system(\"mkdir -p /mnt/local_storage/dspy/finetuning/\")\n",
    "\n",
    "# os.system(f\"anyscale job submit --config-file {compute_config_path} --wait\")\n",
    "FINETUNE = False\n",
    "if FINETUNE:\n",
    "    process = subprocess.Popen(compute_config[\"entrypoint\"], shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n",
    "\n",
    "    # Stream the output line by line\n",
    "    for line in process.stdout:\n",
    "        print(line.decode(), end=\"\")\n",
    "\n",
    "    # Wait for the process to finish and get the return code\n",
    "    process.wait()\n",
    "    \n",
    "    # storage_url = line\n",
    "    decoded_string = line.decode('utf-8')\n",
    "\n",
    "    # Note this is a bad way to do this\n",
    "    if \"Best\" in decoded_string:\n",
    "        storage_url = re.search(r's3://[^\\s]+', decoded_string).group().split(\"s3://\")[-1]\n",
    "    else:\n",
    "        print(\"rip\")\n",
    "    # Use regex to extract the S3 path\n",
    "else:\n",
    "    storage_url = 'anyscale-production-data-cld-1j41ls4gwkga4pwp8nbql6f239/org_4snvy99zwbmh4gbtk64jfqggmj/cld_1j41ls4gwkga4pwp8nbql6f239/artifact_storage/lora_fine_tuning/meta-llama/Meta-Llama-3-8B-Instruct:isaac:pvslq'\n",
    "\n",
    "bucket_name = storage_url.split(\"/\")[0]\n",
    "prefix = \"/\".join(storage_url.split(\"/\")[1:])\n",
    "\n",
    "# Start the remote training\n",
    "# job_id = lm._start_remote_training(**kwargs)\n",
    "storage_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import boto3\n",
    "s3 = boto3.client('s3')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/local_storage/dspy/finetuning/Meta-Llama-3-8B-Instruct_isaac_pvslq/README.md already exists. Skipping download.\n",
      "/mnt/local_storage/dspy/finetuning/Meta-Llama-3-8B-Instruct_isaac_pvslq/adapter_config.json already exists. Skipping download.\n",
      "/mnt/local_storage/dspy/finetuning/Meta-Llama-3-8B-Instruct_isaac_pvslq/adapter_model.safetensors already exists. Skipping download.\n",
      "/mnt/local_storage/dspy/finetuning/Meta-Llama-3-8B-Instruct_isaac_pvslq/config.json already exists. Skipping download.\n",
      "/mnt/local_storage/dspy/finetuning/Meta-Llama-3-8B-Instruct_isaac_pvslq/new_embeddings.safetensors already exists. Skipping download.\n",
      "/mnt/local_storage/dspy/finetuning/Meta-Llama-3-8B-Instruct_isaac_pvslq/rayllm_generation_config.json already exists. Skipping download.\n",
      "/mnt/local_storage/dspy/finetuning/Meta-Llama-3-8B-Instruct_isaac_pvslq/special_tokens_map.json already exists. Skipping download.\n",
      "/mnt/local_storage/dspy/finetuning/Meta-Llama-3-8B-Instruct_isaac_pvslq/tokenizer.json already exists. Skipping download.\n",
      "/mnt/local_storage/dspy/finetuning/Meta-Llama-3-8B-Instruct_isaac_pvslq/tokenizer_config.json already exists. Skipping download.\n"
     ]
    }
   ],
   "source": [
    "# List objects in the prefix\n",
    "response = s3.list_objects_v2(Bucket=bucket_name, Prefix=prefix)\n",
    "\n",
    "# Extract the last part of the key prefix\n",
    "prefix_last_part = prefix.split(\"/\")[-1]\n",
    "\n",
    "# Create the local file path under /finetuning/{LAST PART OF S3 PREFIX}\n",
    "local_dir = os.path.join('/mnt/local_storage/dspy/finetuning', prefix_last_part)\n",
    "local_dir = local_dir.replace(\":\", \"_\")\n",
    "\n",
    "if not os.path.exists(local_dir):\n",
    "    os.makedirs(local_dir)\n",
    "\n",
    "# Check if objects are returned\n",
    "if 'Contents' in response:\n",
    "    for obj in response['Contents']:\n",
    "        key = obj['Key']\n",
    "        \n",
    "        # Create the local file path\n",
    "        local_filename = os.path.join(local_dir, key.split(\"/\")[-1])\n",
    "\n",
    "\n",
    "        # Dont redownload the same file\n",
    "        if os.path.exists(local_filename):\n",
    "            print(f\"{local_filename} already exists. Skipping download.\")\n",
    "            continue\n",
    "\n",
    "        # Download the object\n",
    "        s3.download_file(bucket_name, key, local_filename)\n",
    "        print(f\"{key} downloaded successfully to {local_filename}.\")\n",
    "else:\n",
    "    print(\"No objects found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import transformers\n",
    "from llmforge.file_transfer import ModelDownloader\n",
    "from llmforge.lora.utils import load_peft_model\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# Load the model 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 , local_files_only=True\n",
    "\n",
    "NUM_THREADS = 1\n",
    "model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "lora_source_path = local_dir\n",
    "# downloader = ModelDownloader(model_id=model_id, source_path=lora_source_path)\n",
    "# local_lora_path = downloader.download(tokenizer_only=False)\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_id) \n",
    "# peft_model = load_peft_model(lora_path=local_lora_path, base_ckpt_path=model_id, tokenizer_len=len(tokenizer), device=\"auto\")\n",
    "\n",
    "# # Test the model\n",
    "# input_text = \"What is the capital of France?\"\n",
    "# input_ids = tokenizer(input_text, return_tensors=\"pt\").to(\"cuda\").input_ids\n",
    "# output = peft_model.generate(input_ids, max_length=100)\n",
    "# output_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "# print(output_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dsp.modules.hf import HFProvidedModel\n",
    "# hf_lm = HFProvidedModel(model=peft_model, tokenizer=tokenizer, max_tokens=250, pad_token_id=tokenizer.eos_token_id) # , do_sample=True, temperature=0.3, top_k=50, top_p=0.95\n",
    "\n",
    "# dspy.settings.configure(lm=hf_lm)\n",
    "dspy.settings.configure(experimental=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred = dspy.Predict(\"question -> answer\")\n",
    "# print(pred(question=\"What is the capital of France?\").answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raise SystemExit(\"Stop right there!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMP_SKIP = True\n",
    "# Wait for the training to complete\n",
    "\n",
    "if not TEMP_SKIP:\n",
    "    lm.wait_for_training()\n",
    "\n",
    "    # lm._deploy_tuned_model()\n",
    "\n",
    "    # Retrieve the trained model and return a copy\n",
    "    lm.retrieve_trained_model_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dsp.modules.lm import TrainingMethod\n",
    "\n",
    "if not TEMP_SKIP:\n",
    "    future_lm = lm.get_finetune(method=TrainingMethod.SFT, train_path=\"trainset_data.jsonl\", eval_path=\"devset_data.jsonl\", hyperparameters={\"n_epochs\": 1})\n",
    "    finetuned_lm = future_lm.result()\n",
    "    finetuned_lm.kwargs[\"temperature\"] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert finetuned_lm.kwargs[\"model\"] != lm.kwargs[\"model\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "basicmh_bs_ft = BasicMH(**program_params)\n",
    "# basicmh_bs_ft._set_all_predictor_lms(hf_lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "RECOMPILE_FT_MODEL = False\n",
    "os.environ[\"DSP_CACHEBOOL\"] = \"False\"\n",
    "\n",
    "if RECOMPILE_FT_MODEL:\n",
    "    max_bootstrapped_demos, max_labeled_demos, num_candidate_programs = 3,3,6\n",
    "    config = dict(max_bootstrapped_demos=max_bootstrapped_demos, num_candidate_programs=num_candidate_programs, num_threads=NUM_THREADS)\n",
    "    bsfsrs_teleprompter = BootstrapFewShotWithRandomSearch(metric=metric, **config)\n",
    "    basicmh_bs_ft_bs = bsfsrs_teleprompter.compile(student=basicmh_bs_ft, trainset=trainset[100:], valset=devset[:250])\n",
    "    basicmh_bs_ft_bs.save('mini_bs_ft_bs_hpqa_100.json')\n",
    "    # basicmh_bs_ft_bs._set_all_predictor_lms(hf_lm)\n",
    "else:\n",
    "    basicmh_bs_ft_bs = BasicMH(**program_params)\n",
    "    # basicmh_bs_ft_bs.load('mini_bs_ft_bs_hpqa_100.json')\n",
    "    # basicmh_bs_ft_bs._set_all_predictor_lms(hf_lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/local_storage/dspy/finetuning/Meta-Llama-3-8B-Instruct_isaac_pvslq meta-llama/Meta-Llama-3-8B-Instruct /mnt/local_storage/dspy/finetuning/Meta-Llama-3-8B-Instruct_isaac_pvslq\n"
     ]
    }
   ],
   "source": [
    "print(local_dir, model_id, lora_source_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "import numpy as np\n",
    "\n",
    "# @ray.remote\n",
    "class DSPyActor:\n",
    "    def __init__(self):\n",
    "\n",
    "        model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "        lora_source_path = local_dir\n",
    "        downloader = ModelDownloader(model_id=model_id, source_path=lora_source_path)\n",
    "        local_lora_path = downloader.download(tokenizer_only=False)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "        self.peft_model = load_peft_model(lora_path=local_lora_path, base_ckpt_path=model_id, tokenizer_len=len(self.tokenizer), device=\"cuda\")\n",
    "        \n",
    "        self.program = BasicMH()\n",
    "        self.lm = HFProvidedModel(model=self.peft_model, tokenizer=self.tokenizer, max_tokens=251, pad_token_id=self.tokenizer.eos_token_id)\n",
    "\n",
    "    def __call__(self, batch: Dict[str, np.ndarray]):\n",
    "        print(batch)\n",
    "        # return {\"output\": [1]}\n",
    "        item = batch[\"item\"][0]\n",
    "        with dspy.context(lm=self.lm):\n",
    "            return {\"output\":self.program(question=item.question)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Good stuff is above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# actor = DSPyActor()\n",
    "\n",
    "# actor({\"data\": [{\"question\": \"What is the capital of France?\"}]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-27 19:00:20,754\tINFO streaming_executor.py:108 -- Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-08-27_18-52-28_256774_2706/logs/ray-data\n",
      "2024-08-27 19:00:20,755\tINFO streaming_executor.py:109 -- Execution plan of Dataset: InputDataBuffer[Input] -> ActorPoolMapOperator[MapBatches(DSPyActor)] -> LimitOperator[limit=10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_MapWorker pid=18865, ip=10.0.14.83)\u001b[0m [2024-08-27 19:00:24,329] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "\u001b[33m(raylet)\u001b[0m Traceback (most recent call last):\n",
      "  File \"python/ray/_raylet.pyx\", line 1848, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 1882, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 985, in ray._raylet.raise_if_dependency_failed\n",
      "ray.exceptions.RaySystemError: System error: No module named 'magicattr'\n",
      "traceback: Traceback (most recent call last):\n",
      "  File \"/home/ray/anaconda3/lib/python3.11/site-packages/ray/_private/serialization.py\", line 423, in deserialize_objects\n",
      "    obj = self._deserialize_object(data, metadata, object_ref)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ray/anaconda3/lib/python3.11/site-packages/ray/_private/serialization.py\", line 280, in _deserialize_object\n",
      "    return self._deserialize_msgpack_data(data, metadata_fields)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ray/anaconda3/lib/python3.11/site-packages/ray/_private/serialization.py\", line 235, in _deserialize_msgpack_data\n",
      "    python_objects = self._deserialize_pickle5_data(pickle5_data)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ray/anaconda3/lib/python3.11/site-packages/ray/_private/serialization.py\", line 225, in _deserialize_pickle5_data\n",
      "    obj = pickle.loads(in_band)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ray/session_2024-08-27_18-52-28_256774_2706/runtime_resources/py_modules_files/_ray_pkg_4a04a2850f39c81c/dspy/__init__.py\", line 4, in <module>\n",
      "    from .predict import *\n",
      "  File \"/tmp/ray/session_2024-08-27_18-52-28_256774_2706/runtime_resources/py_modules_files/_ray_pkg_4a04a2850f39c81c/dspy/predict/__init__.py\", line 1, in <module>\n",
      "    from .aggregation import majority\n",
      "  File \"/tmp/ray/session_2024-08-27_18-52-28_256774_2706/runtime_resources/py_modules_files/_ray_pkg_4a04a2850f39c81c/dspy/predict/aggregation.py\", line 2, in <module>\n",
      "    from dspy.primitives.prediction import Completions, Prediction\n",
      "  File \"/tmp/ray/session_2024-08-27_18-52-28_256774_2706/runtime_resources/py_modules_files/_ray_pkg_4a04a2850f39c81c/dspy/primitives/__init__.py\", line 4, in <module>\n",
      "    from .program import *\n",
      "  File \"/tmp/ray/session_2024-08-27_18-52-28_256774_2706/runtime_resources/py_modules_files/_ray_pkg_4a04a2850f39c81c/dspy/primitives/program.py\", line 4, in <module>\n",
      "    import magicattr\n",
      "ModuleNotFoundError: No module named 'magicattr'\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"python/ray/_raylet.pyx\", line 2293, in ray._raylet.task_execution_handler\n",
      "  File \"python/ray/_raylet.pyx\", line 2189, in ray._raylet.execute_task_with_cancellation_handler\n",
      "  File \"python/ray/_raylet.pyx\", line 1844, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 1845, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 2083, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 1076, in ray._raylet.store_task_errors\n",
      "  File \"/home/ray/anaconda3/lib/python3.11/site-packages/ray/util/tracing/tracing_helper.py\", line 467, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ray/anaconda3/lib/python3.11/site-packages/ray/data/_internal/execution/operators/actor_pool_map_operator.py\", line 372, in __repr__\n",
      "    return f\"MapWorker({self.src_fn_name})\"\n",
      "                        ^^^^^^^^^^^^^^^^\n",
      "AttributeError: '_MapWorker' object has no attribute 'src_fn_name'\n",
      "An unexpected internal error occurred while the worker was executing a task.\n",
      "\u001b[33m(raylet)\u001b[0m A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: ffffffffffffffffdf9c5a84d9aa50212624964604000000 Worker ID: dc887a5974757930c75e2a6a870c0fb578f277fd8c193dc65de6a8bb Node ID: c754e0939fd681cf99d21cc28faa3c642f74dba9055f314051eb4c62 Worker IP address: 10.0.14.83 Worker port: 10118 Worker PID: 18865 Worker exit type: SYSTEM_ERROR Worker exit detail: Worker exits unexpectedly. Worker exits with an exit code None. Traceback (most recent call last):\n",
      "  File \"python/ray/_raylet.pyx\", line 1848, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 1882, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 985, in ray._raylet.raise_if_dependency_failed\n",
      "ray.exceptions.RaySystemError: System error: No module named 'magicattr'\n",
      "traceback: Traceback (most recent call last):\n",
      "  File \"/home/ray/anaconda3/lib/python3.11/site-packages/ray/_private/serialization.py\", line 423, in deserialize_objects\n",
      "    obj = self._deserialize_object(data, metadata, object_ref)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ray/anaconda3/lib/python3.11/site-packages/ray/_private/serialization.py\", line 280, in _deserialize_object\n",
      "    return self._deserialize_msgpack_data(data, metadata_fields)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ray/anaconda3/lib/python3.11/site-packages/ray/_private/serialization.py\", line 235, in _deserialize_msgpack_data\n",
      "    python_objects = self._deserialize_pickle5_data(pickle5_data)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ray/anaconda3/lib/python3.11/site-packages/ray/_private/serialization.py\", line 225, in _deserialize_pickle5_data\n",
      "    obj = pickle.loads(in_band)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ray/session_2024-08-27_18-52-28_256774_2706/runtime_resources/py_modules_files/_ray_pkg_4a04a2850f39c81c/dspy/__init__.py\", line 4, in <module>\n",
      "    from .predict import *\n",
      "  File \"/tmp/ray/session_2024-08-27_18-52-28_256774_2706/runtime_resources/py_modules_files/_ray_pkg_4a04a2850f39c81c/dspy/predict/__init__.py\", line 1, in <module>\n",
      "    from .aggregation import majority\n",
      "  File \"/tmp/ray/session_2024-08-27_18-52-28_256774_2706/runtime_resources/py_modules_files/_ray_pkg_4a04a2850f39c81c/dspy/predict/aggregation.py\", line 2, in <module>\n",
      "    from dspy.primitives.prediction import Completions, Prediction\n",
      "  File \"/tmp/ray/session_2024-08-27_18-52-28_256774_2706/runtime_resources/py_modules_files/_ray_pkg_4a04a2850f39c81c/dspy/primitives/__init__.py\", line 4, in <module>\n",
      "    from .program import *\n",
      "  File \"/tmp/ray/session_2024-08-27_18-52-28_256774_2706/runtime_resources/py_modules_files/_ray_pkg_4a04a2850f39c81c/dspy/primitives/program.py\", line 4, in <module>\n",
      "    import magicattr\n",
      "ModuleNotFoundError: No module named 'magicattr'\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"python/ray/_raylet.pyx\", line 2293, in ray._raylet.task_execution_handler\n",
      "  File \"python/ray/_raylet.pyx\", line 2189, in ray._raylet.execute_task_with_cancellation_handler\n",
      "  File \"python/ray/_raylet.pyx\", line 1844, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 1845, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 2083, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 1076, in ray._raylet.store_task_errors\n",
      "  File \"/home/ray/anaconda3/lib/python3.11/site-packages/ray/util/tracing/tracing_helper.py\", line 467, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ray/anaconda3/lib/python3.11/site-packages/ray/data/_internal/execution/operators/actor_pool_map_operator.py\", line 372, in __repr__\n",
      "    return f\"MapWorker({self.src_fn_name})\"\n",
      "                        ^^^^^^^^^^^^^^^^\n",
      "AttributeError: '_MapWorker' object has no attribute 'src_fn_name'\n",
      "An unexpected internal error occurred while the worker was executing a task.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_MapWorker pid=18866, ip=10.0.14.83)\u001b[0m No module named 'magicattr'\n",
      "\u001b[36m(_MapWorker pid=18866, ip=10.0.14.83)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_MapWorker pid=18866, ip=10.0.14.83)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.11/site-packages/ray/_private/serialization.py\", line 423, in deserialize_objects\n",
      "\u001b[36m(_MapWorker pid=18866, ip=10.0.14.83)\u001b[0m     obj = self._deserialize_object(data, metadata, object_ref)\n",
      "\u001b[36m(_MapWorker pid=18866, ip=10.0.14.83)\u001b[0m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_MapWorker pid=18866, ip=10.0.14.83)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.11/site-packages/ray/_private/serialization.py\", line 280, in _deserialize_object\n",
      "\u001b[36m(_MapWorker pid=18866, ip=10.0.14.83)\u001b[0m     return self._deserialize_msgpack_data(data, metadata_fields)\n",
      "\u001b[36m(_MapWorker pid=18866, ip=10.0.14.83)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_MapWorker pid=18866, ip=10.0.14.83)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.11/site-packages/ray/_private/serialization.py\", line 235, in _deserialize_msgpack_data\n",
      "\u001b[36m(_MapWorker pid=18866, ip=10.0.14.83)\u001b[0m     python_objects = self._deserialize_pickle5_data(pickle5_data)\n",
      "\u001b[36m(_MapWorker pid=18866, ip=10.0.14.83)\u001b[0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_MapWorker pid=18866, ip=10.0.14.83)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.11/site-packages/ray/_private/serialization.py\", line 225, in _deserialize_pickle5_data\n",
      "\u001b[36m(_MapWorker pid=18866, ip=10.0.14.83)\u001b[0m     obj = pickle.loads(in_band)\n",
      "\u001b[36m(_MapWorker pid=18866, ip=10.0.14.83)\u001b[0m           ^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_MapWorker pid=18866, ip=10.0.14.83)\u001b[0m   File \"/tmp/ray/session_2024-08-27_18-52-28_256774_2706/runtime_resources/py_modules_files/_ray_pkg_4a04a2850f39c81c/dspy/__init__.py\", line 4, in <module>\n",
      "\u001b[36m(_MapWorker pid=18866, ip=10.0.14.83)\u001b[0m     from .predict import *\n",
      "\u001b[36m(_MapWorker pid=18866, ip=10.0.14.83)\u001b[0m   File \"/tmp/ray/session_2024-08-27_18-52-28_256774_2706/runtime_resources/py_modules_files/_ray_pkg_4a04a2850f39c81c/dspy/predict/__init__.py\", line 1, in <module>\n",
      "\u001b[36m(_MapWorker pid=18866, ip=10.0.14.83)\u001b[0m     from .aggregation import majority\n",
      "\u001b[36m(_MapWorker pid=18866, ip=10.0.14.83)\u001b[0m   File \"/tmp/ray/session_2024-08-27_18-52-28_256774_2706/runtime_resources/py_modules_files/_ray_pkg_4a04a2850f39c81c/dspy/predict/aggregation.py\", line 2, in <module>\n",
      "\u001b[36m(_MapWorker pid=18866, ip=10.0.14.83)\u001b[0m     from dspy.primitives.prediction import Completions, Prediction\n",
      "\u001b[36m(_MapWorker pid=18866, ip=10.0.14.83)\u001b[0m   File \"/tmp/ray/session_2024-08-27_18-52-28_256774_2706/runtime_resources/py_modules_files/_ray_pkg_4a04a2850f39c81c/dspy/primitives/__init__.py\", line 4, in <module>\n",
      "\u001b[36m(_MapWorker pid=18866, ip=10.0.14.83)\u001b[0m     from .program import *\n",
      "\u001b[36m(_MapWorker pid=18866, ip=10.0.14.83)\u001b[0m   File \"/tmp/ray/session_2024-08-27_18-52-28_256774_2706/runtime_resources/py_modules_files/_ray_pkg_4a04a2850f39c81c/dspy/primitives/program.py\", line 4, in <module>\n",
      "\u001b[36m(_MapWorker pid=18866, ip=10.0.14.83)\u001b[0m     import magicattr\n",
      "\u001b[36m(_MapWorker pid=18866, ip=10.0.14.83)\u001b[0m ModuleNotFoundError: No module named 'magicattr'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_MapWorker pid=19847, ip=10.0.14.83)\u001b[0m [2024-08-27 19:00:30,504] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[33m(raylet)\u001b[0m Traceback (most recent call last):\n",
      "  File \"python/ray/_raylet.pyx\", line 1848, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 1882, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 985, in ray._raylet.raise_if_dependency_failed\n",
      "ray.exceptions.RaySystemError: System error: No module named 'magicattr'\n",
      "traceback: Traceback (most recent call last):\n",
      "  File \"/home/ray/anaconda3/lib/python3.11/site-packages/ray/_private/serialization.py\", line 423, in deserialize_objects\n",
      "    obj = self._deserialize_object(data, metadata, object_ref)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ray/anaconda3/lib/python3.11/site-packages/ray/_private/serialization.py\", line 280, in _deserialize_object\n",
      "    return self._deserialize_msgpack_data(data, metadata_fields)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ray/anaconda3/lib/python3.11/site-packages/ray/_private/serialization.py\", line 235, in _deserialize_msgpack_data\n",
      "    python_objects = self._deserialize_pickle5_data(pickle5_data)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ray/anaconda3/lib/python3.11/site-packages/ray/_private/serialization.py\", line 225, in _deserialize_pickle5_data\n",
      "    obj = pickle.loads(in_band)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ray/session_2024-08-27_18-52-28_256774_2706/runtime_resources/py_modules_files/_ray_pkg_4a04a2850f39c81c/dspy/__init__.py\", line 4, in <module>\n",
      "    from .predict import *\n",
      "  File \"/tmp/ray/session_2024-08-27_18-52-28_256774_2706/runtime_resources/py_modules_files/_ray_pkg_4a04a2850f39c81c/dspy/predict/__init__.py\", line 1, in <module>\n",
      "    from .aggregation import majority\n",
      "  File \"/tmp/ray/session_2024-08-27_18-52-28_256774_2706/runtime_resources/py_modules_files/_ray_pkg_4a04a2850f39c81c/dspy/predict/aggregation.py\", line 2, in <module>\n",
      "    from dspy.primitives.prediction import Completions, Prediction\n",
      "  File \"/tmp/ray/session_2024-08-27_18-52-28_256774_2706/runtime_resources/py_modules_files/_ray_pkg_4a04a2850f39c81c/dspy/primitives/__init__.py\", line 4, in <module>\n",
      "    from .program import *\n",
      "  File \"/tmp/ray/session_2024-08-27_18-52-28_256774_2706/runtime_resources/py_modules_files/_ray_pkg_4a04a2850f39c81c/dspy/primitives/program.py\", line 4, in <module>\n",
      "    import magicattr\n",
      "ModuleNotFoundError: No module named 'magicattr'\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"python/ray/_raylet.pyx\", line 2293, in ray._raylet.task_execution_handler\n",
      "  File \"python/ray/_raylet.pyx\", line 2189, in ray._raylet.execute_task_with_cancellation_handler\n",
      "  File \"python/ray/_raylet.pyx\", line 1844, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 1845, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 2083, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 1076, in ray._raylet.store_task_errors\n",
      "  File \"/home/ray/anaconda3/lib/python3.11/site-packages/ray/util/tracing/tracing_helper.py\", line 467, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ray/anaconda3/lib/python3.11/site-packages/ray/data/_internal/execution/operators/actor_pool_map_operator.py\", line 372, in __repr__\n",
      "    return f\"MapWorker({self.src_fn_name})\"\n",
      "                        ^^^^^^^^^^^^^^^^\n",
      "AttributeError: '_MapWorker' object has no attribute 'src_fn_name'\n",
      "An unexpected internal error occurred while the worker was executing a task.\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[33m(raylet)\u001b[0m A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: ffffffffffffffff6dbbd1e4ad9c99c3f23f912504000000 Worker ID: 776587a82986fca5ef4c8e718aaf79e28491bc15d030064bf2aa8c6a Node ID: c754e0939fd681cf99d21cc28faa3c642f74dba9055f314051eb4c62 Worker IP address: 10.0.14.83 Worker port: 10115 Worker PID: 18868 Worker exit type: SYSTEM_ERROR Worker exit detail: Worker exits unexpectedly. Worker exits with an exit code None. Traceback (most recent call last):\n",
      "  File \"python/ray/_raylet.pyx\", line 1848, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 1882, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 985, in ray._raylet.raise_if_dependency_failed\n",
      "ray.exceptions.RaySystemError: System error: No module named 'magicattr'\n",
      "traceback: Traceback (most recent call last):\n",
      "  File \"/home/ray/anaconda3/lib/python3.11/site-packages/ray/_private/serialization.py\", line 423, in deserialize_objects\n",
      "    obj = self._deserialize_object(data, metadata, object_ref)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ray/anaconda3/lib/python3.11/site-packages/ray/_private/serialization.py\", line 280, in _deserialize_object\n",
      "    return self._deserialize_msgpack_data(data, metadata_fields)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ray/anaconda3/lib/python3.11/site-packages/ray/_private/serialization.py\", line 235, in _deserialize_msgpack_data\n",
      "    python_objects = self._deserialize_pickle5_data(pickle5_data)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ray/anaconda3/lib/python3.11/site-packages/ray/_private/serialization.py\", line 225, in _deserialize_pickle5_data\n",
      "    obj = pickle.loads(in_band)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ray/session_2024-08-27_18-52-28_256774_2706/runtime_resources/py_modules_files/_ray_pkg_4a04a2850f39c81c/dspy/__init__.py\", line 4, in <module>\n",
      "    from .predict import *\n",
      "  File \"/tmp/ray/session_2024-08-27_18-52-28_256774_2706/runtime_resources/py_modules_files/_ray_pkg_4a04a2850f39c81c/dspy/predict/__init__.py\", line 1, in <module>\n",
      "    from .aggregation import majority\n",
      "  File \"/tmp/ray/session_2024-08-27_18-52-28_256774_2706/runtime_resources/py_modules_files/_ray_pkg_4a04a2850f39c81c/dspy/predict/aggregation.py\", line 2, in <module>\n",
      "    from dspy.primitives.prediction import Completions, Prediction\n",
      "  File \"/tmp/ray/session_2024-08-27_18-52-28_256774_2706/runtime_resources/py_modules_files/_ray_pkg_4a04a2850f39c81c/dspy/primitives/__init__.py\", line 4, in <module>\n",
      "    from .program import *\n",
      "  File \"/tmp/ray/session_2024-08-27_18-52-28_256774_2706/runtime_resources/py_modules_files/_ray_pkg_4a04a2850f39c81c/dspy/primitives/program.py\", line 4, in <module>\n",
      "    import magicattr\n",
      "ModuleNotFoundError: No module named 'magicattr'\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"python/ray/_raylet.pyx\", line 2293, in ray._raylet.task_execution_handler\n",
      "  File \"python/ray/_raylet.pyx\", line 2189, in ray._raylet.execute_task_with_cancellation_handler\n",
      "  File \"python/ray/_raylet.pyx\", line 1844, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 1845, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 2083, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 1076, in ray._raylet.store_task_errors\n",
      "  File \"/home/ray/anaconda3/lib/python3.11/site-packages/ray/util/tracing/tracing_helper.py\", line 467, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ray/anaconda3/lib/python3.11/site-packages/ray/data/_internal/execution/operators/actor_pool_map_operator.py\", line 372, in __repr__\n",
      "    return f\"MapWorker({self.src_fn_name})\"\n",
      "                        ^^^^^^^^^^^^^^^^\n",
      "AttributeError: '_MapWorker' object has no attribute 'src_fn_name'\n",
      "An unexpected internal error occurred while the worker was executing a task.\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_MapWorker pid=19853, ip=10.0.14.83)\u001b[0m No module named 'magicattr'\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=19853, ip=10.0.14.83)\u001b[0m Traceback (most recent call last):\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=19853, ip=10.0.14.83)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.11/site-packages/ray/_private/serialization.py\", line 423, in deserialize_objects\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=19853, ip=10.0.14.83)\u001b[0m     obj = self._deserialize_object(data, metadata, object_ref)\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=19853, ip=10.0.14.83)\u001b[0m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=19853, ip=10.0.14.83)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.11/site-packages/ray/_private/serialization.py\", line 280, in _deserialize_object\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=19853, ip=10.0.14.83)\u001b[0m     return self._deserialize_msgpack_data(data, metadata_fields)\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=19853, ip=10.0.14.83)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=19853, ip=10.0.14.83)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.11/site-packages/ray/_private/serialization.py\", line 235, in _deserialize_msgpack_data\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=19853, ip=10.0.14.83)\u001b[0m     python_objects = self._deserialize_pickle5_data(pickle5_data)\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=19853, ip=10.0.14.83)\u001b[0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=19853, ip=10.0.14.83)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.11/site-packages/ray/_private/serialization.py\", line 225, in _deserialize_pickle5_data\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=19853, ip=10.0.14.83)\u001b[0m     obj = pickle.loads(in_band)\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=19853, ip=10.0.14.83)\u001b[0m           ^^^^^^^^^^^^^^^^^^^^^\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=19853, ip=10.0.14.83)\u001b[0m   File \"/tmp/ray/session_2024-08-27_18-52-28_256774_2706/runtime_resources/py_modules_files/_ray_pkg_4a04a2850f39c81c/dspy/primitives/program.py\", line 4, in <module>\u001b[32m [repeated 40x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=19853, ip=10.0.14.83)\u001b[0m     from .predict import *\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=19853, ip=10.0.14.83)\u001b[0m     from .aggregation import majority\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=19853, ip=10.0.14.83)\u001b[0m     from dspy.primitives.prediction import Completions, Prediction\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=19853, ip=10.0.14.83)\u001b[0m     from .program import *\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=19853, ip=10.0.14.83)\u001b[0m     import magicattr\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=19853, ip=10.0.14.83)\u001b[0m ModuleNotFoundError: No module named 'magicattr'\u001b[32m [repeated 8x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_MapWorker pid=20807, ip=10.0.14.83)\u001b[0m [2024-08-27 19:00:35,682] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[33m(raylet)\u001b[0m Traceback (most recent call last):\n",
      "  File \"python/ray/_raylet.pyx\", line 1848, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 1882, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 985, in ray._raylet.raise_if_dependency_failed\n",
      "ray.exceptions.RaySystemError: System error: No module named 'magicattr'\n",
      "traceback: Traceback (most recent call last):\n",
      "  File \"/home/ray/anaconda3/lib/python3.11/site-packages/ray/_private/serialization.py\", line 423, in deserialize_objects\n",
      "    obj = self._deserialize_object(data, metadata, object_ref)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ray/anaconda3/lib/python3.11/site-packages/ray/_private/serialization.py\", line 280, in _deserialize_object\n",
      "    return self._deserialize_msgpack_data(data, metadata_fields)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ray/anaconda3/lib/python3.11/site-packages/ray/_private/serialization.py\", line 235, in _deserialize_msgpack_data\n",
      "    python_objects = self._deserialize_pickle5_data(pickle5_data)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ray/anaconda3/lib/python3.11/site-packages/ray/_private/serialization.py\", line 225, in _deserialize_pickle5_data\n",
      "    obj = pickle.loads(in_band)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ray/session_2024-08-27_18-52-28_256774_2706/runtime_resources/py_modules_files/_ray_pkg_4a04a2850f39c81c/dspy/__init__.py\", line 4, in <module>\n",
      "    from .predict import *\n",
      "  File \"/tmp/ray/session_2024-08-27_18-52-28_256774_2706/runtime_resources/py_modules_files/_ray_pkg_4a04a2850f39c81c/dspy/predict/__init__.py\", line 1, in <module>\n",
      "    from .aggregation import majority\n",
      "  File \"/tmp/ray/session_2024-08-27_18-52-28_256774_2706/runtime_resources/py_modules_files/_ray_pkg_4a04a2850f39c81c/dspy/predict/aggregation.py\", line 2, in <module>\n",
      "    from dspy.primitives.prediction import Completions, Prediction\n",
      "  File \"/tmp/ray/session_2024-08-27_18-52-28_256774_2706/runtime_resources/py_modules_files/_ray_pkg_4a04a2850f39c81c/dspy/primitives/__init__.py\", line 4, in <module>\n",
      "    from .program import *\n",
      "  File \"/tmp/ray/session_2024-08-27_18-52-28_256774_2706/runtime_resources/py_modules_files/_ray_pkg_4a04a2850f39c81c/dspy/primitives/program.py\", line 4, in <module>\n",
      "    import magicattr\n",
      "ModuleNotFoundError: No module named 'magicattr'\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"python/ray/_raylet.pyx\", line 2293, in ray._raylet.task_execution_handler\n",
      "  File \"python/ray/_raylet.pyx\", line 2189, in ray._raylet.execute_task_with_cancellation_handler\n",
      "  File \"python/ray/_raylet.pyx\", line 1844, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 1845, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 2083, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 1076, in ray._raylet.store_task_errors\n",
      "  File \"/home/ray/anaconda3/lib/python3.11/site-packages/ray/util/tracing/tracing_helper.py\", line 467, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ray/anaconda3/lib/python3.11/site-packages/ray/data/_internal/execution/operators/actor_pool_map_operator.py\", line 372, in __repr__\n",
      "    return f\"MapWorker({self.src_fn_name})\"\n",
      "                        ^^^^^^^^^^^^^^^^\n",
      "AttributeError: '_MapWorker' object has no attribute 'src_fn_name'\n",
      "An unexpected internal error occurred while the worker was executing a task.\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[33m(raylet)\u001b[0m A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: ffffffffffffffffee8d1497bf640fa9e50a571d04000000 Worker ID: 9d443d8083bb711ba2ba66c5825d276f1cc8441b5a0a6eaf9e895547 Node ID: c754e0939fd681cf99d21cc28faa3c642f74dba9055f314051eb4c62 Worker IP address: 10.0.14.83 Worker port: 10131 Worker PID: 20807 Worker exit type: SYSTEM_ERROR Worker exit detail: Worker exits unexpectedly. Worker exits with an exit code None. Traceback (most recent call last):\n",
      "  File \"python/ray/_raylet.pyx\", line 1848, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 1882, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 985, in ray._raylet.raise_if_dependency_failed\n",
      "ray.exceptions.RaySystemError: System error: No module named 'magicattr'\n",
      "traceback: Traceback (most recent call last):\n",
      "  File \"/home/ray/anaconda3/lib/python3.11/site-packages/ray/_private/serialization.py\", line 423, in deserialize_objects\n",
      "    obj = self._deserialize_object(data, metadata, object_ref)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ray/anaconda3/lib/python3.11/site-packages/ray/_private/serialization.py\", line 280, in _deserialize_object\n",
      "    return self._deserialize_msgpack_data(data, metadata_fields)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ray/anaconda3/lib/python3.11/site-packages/ray/_private/serialization.py\", line 235, in _deserialize_msgpack_data\n",
      "    python_objects = self._deserialize_pickle5_data(pickle5_data)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ray/anaconda3/lib/python3.11/site-packages/ray/_private/serialization.py\", line 225, in _deserialize_pickle5_data\n",
      "    obj = pickle.loads(in_band)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ray/session_2024-08-27_18-52-28_256774_2706/runtime_resources/py_modules_files/_ray_pkg_4a04a2850f39c81c/dspy/__init__.py\", line 4, in <module>\n",
      "    from .predict import *\n",
      "  File \"/tmp/ray/session_2024-08-27_18-52-28_256774_2706/runtime_resources/py_modules_files/_ray_pkg_4a04a2850f39c81c/dspy/predict/__init__.py\", line 1, in <module>\n",
      "    from .aggregation import majority\n",
      "  File \"/tmp/ray/session_2024-08-27_18-52-28_256774_2706/runtime_resources/py_modules_files/_ray_pkg_4a04a2850f39c81c/dspy/predict/aggregation.py\", line 2, in <module>\n",
      "    from dspy.primitives.prediction import Completions, Prediction\n",
      "  File \"/tmp/ray/session_2024-08-27_18-52-28_256774_2706/runtime_resources/py_modules_files/_ray_pkg_4a04a2850f39c81c/dspy/primitives/__init__.py\", line 4, in <module>\n",
      "    from .program import *\n",
      "  File \"/tmp/ray/session_2024-08-27_18-52-28_256774_2706/runtime_resources/py_modules_files/_ray_pkg_4a04a2850f39c81c/dspy/primitives/program.py\", line 4, in <module>\n",
      "    import magicattr\n",
      "ModuleNotFoundError: No module named 'magicattr'\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"python/ray/_raylet.pyx\", line 2293, in ray._raylet.task_execution_handler\n",
      "  File \"python/ray/_raylet.pyx\", line 2189, in ray._raylet.execute_task_with_cancellation_handler\n",
      "  File \"python/ray/_raylet.pyx\", line 1844, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 1845, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 2083, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 1076, in ray._raylet.store_task_errors\n",
      "  File \"/home/ray/anaconda3/lib/python3.11/site-packages/ray/util/tracing/tracing_helper.py\", line 467, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ray/anaconda3/lib/python3.11/site-packages/ray/data/_internal/execution/operators/actor_pool_map_operator.py\", line 372, in __repr__\n",
      "    return f\"MapWorker({self.src_fn_name})\"\n",
      "                        ^^^^^^^^^^^^^^^^\n",
      "AttributeError: '_MapWorker' object has no attribute 'src_fn_name'\n",
      "An unexpected internal error occurred while the worker was executing a task.\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_MapWorker pid=20823, ip=10.0.14.83)\u001b[0m No module named 'magicattr'\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=20823, ip=10.0.14.83)\u001b[0m Traceback (most recent call last):\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=20823, ip=10.0.14.83)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.11/site-packages/ray/_private/serialization.py\", line 423, in deserialize_objects\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=20823, ip=10.0.14.83)\u001b[0m     obj = self._deserialize_object(data, metadata, object_ref)\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=20823, ip=10.0.14.83)\u001b[0m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=20823, ip=10.0.14.83)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.11/site-packages/ray/_private/serialization.py\", line 280, in _deserialize_object\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=20823, ip=10.0.14.83)\u001b[0m     return self._deserialize_msgpack_data(data, metadata_fields)\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=20823, ip=10.0.14.83)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=20823, ip=10.0.14.83)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.11/site-packages/ray/_private/serialization.py\", line 235, in _deserialize_msgpack_data\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=20823, ip=10.0.14.83)\u001b[0m     python_objects = self._deserialize_pickle5_data(pickle5_data)\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=20823, ip=10.0.14.83)\u001b[0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=20823, ip=10.0.14.83)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.11/site-packages/ray/_private/serialization.py\", line 225, in _deserialize_pickle5_data\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=20823, ip=10.0.14.83)\u001b[0m     obj = pickle.loads(in_band)\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=20823, ip=10.0.14.83)\u001b[0m           ^^^^^^^^^^^^^^^^^^^^^\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=20823, ip=10.0.14.83)\u001b[0m   File \"/tmp/ray/session_2024-08-27_18-52-28_256774_2706/runtime_resources/py_modules_files/_ray_pkg_4a04a2850f39c81c/dspy/primitives/program.py\", line 4, in <module>\u001b[32m [repeated 45x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=20823, ip=10.0.14.83)\u001b[0m     from .predict import *\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=20823, ip=10.0.14.83)\u001b[0m     from .aggregation import majority\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=20823, ip=10.0.14.83)\u001b[0m     from dspy.primitives.prediction import Completions, Prediction\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=20823, ip=10.0.14.83)\u001b[0m     from .program import *\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=20823, ip=10.0.14.83)\u001b[0m     import magicattr\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=20823, ip=10.0.14.83)\u001b[0m ModuleNotFoundError: No module named 'magicattr'\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_MapWorker pid=21779, ip=10.0.14.83)\u001b[0m [2024-08-27 19:00:40,781] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[33m(raylet)\u001b[0m Traceback (most recent call last):\n",
      "  File \"python/ray/_raylet.pyx\", line 1848, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 1882, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 985, in ray._raylet.raise_if_dependency_failed\n",
      "ray.exceptions.RaySystemError: System error: No module named 'magicattr'\n",
      "traceback: Traceback (most recent call last):\n",
      "  File \"/home/ray/anaconda3/lib/python3.11/site-packages/ray/_private/serialization.py\", line 423, in deserialize_objects\n",
      "    obj = self._deserialize_object(data, metadata, object_ref)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ray/anaconda3/lib/python3.11/site-packages/ray/_private/serialization.py\", line 280, in _deserialize_object\n",
      "    return self._deserialize_msgpack_data(data, metadata_fields)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ray/anaconda3/lib/python3.11/site-packages/ray/_private/serialization.py\", line 235, in _deserialize_msgpack_data\n",
      "    python_objects = self._deserialize_pickle5_data(pickle5_data)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ray/anaconda3/lib/python3.11/site-packages/ray/_private/serialization.py\", line 225, in _deserialize_pickle5_data\n",
      "    obj = pickle.loads(in_band)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ray/session_2024-08-27_18-52-28_256774_2706/runtime_resources/py_modules_files/_ray_pkg_4a04a2850f39c81c/dspy/__init__.py\", line 4, in <module>\n",
      "    from .predict import *\n",
      "  File \"/tmp/ray/session_2024-08-27_18-52-28_256774_2706/runtime_resources/py_modules_files/_ray_pkg_4a04a2850f39c81c/dspy/predict/__init__.py\", line 1, in <module>\n",
      "    from .aggregation import majority\n",
      "  File \"/tmp/ray/session_2024-08-27_18-52-28_256774_2706/runtime_resources/py_modules_files/_ray_pkg_4a04a2850f39c81c/dspy/predict/aggregation.py\", line 2, in <module>\n",
      "    from dspy.primitives.prediction import Completions, Prediction\n",
      "  File \"/tmp/ray/session_2024-08-27_18-52-28_256774_2706/runtime_resources/py_modules_files/_ray_pkg_4a04a2850f39c81c/dspy/primitives/__init__.py\", line 4, in <module>\n",
      "    from .program import *\n",
      "  File \"/tmp/ray/session_2024-08-27_18-52-28_256774_2706/runtime_resources/py_modules_files/_ray_pkg_4a04a2850f39c81c/dspy/primitives/program.py\", line 4, in <module>\n",
      "    import magicattr\n",
      "ModuleNotFoundError: No module named 'magicattr'\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"python/ray/_raylet.pyx\", line 2293, in ray._raylet.task_execution_handler\n",
      "  File \"python/ray/_raylet.pyx\", line 2189, in ray._raylet.execute_task_with_cancellation_handler\n",
      "  File \"python/ray/_raylet.pyx\", line 1844, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 1845, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 2083, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 1076, in ray._raylet.store_task_errors\n",
      "  File \"/home/ray/anaconda3/lib/python3.11/site-packages/ray/util/tracing/tracing_helper.py\", line 467, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ray/anaconda3/lib/python3.11/site-packages/ray/data/_internal/execution/operators/actor_pool_map_operator.py\", line 372, in __repr__\n",
      "    return f\"MapWorker({self.src_fn_name})\"\n",
      "                        ^^^^^^^^^^^^^^^^\n",
      "AttributeError: '_MapWorker' object has no attribute 'src_fn_name'\n",
      "An unexpected internal error occurred while the worker was executing a task.\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[33m(raylet)\u001b[0m A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: ffffffffffffffffee8d1497bf640fa9e50a571d04000000 Worker ID: dc3646d0a062e217e8728482f644907c6ef25fd5482803e89afcfaa2 Node ID: c754e0939fd681cf99d21cc28faa3c642f74dba9055f314051eb4c62 Worker IP address: 10.0.14.83 Worker port: 10139 Worker PID: 21779 Worker exit type: SYSTEM_ERROR Worker exit detail: Worker exits unexpectedly. Worker exits with an exit code None. Traceback (most recent call last):\n",
      "  File \"python/ray/_raylet.pyx\", line 1848, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 1882, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 985, in ray._raylet.raise_if_dependency_failed\n",
      "ray.exceptions.RaySystemError: System error: No module named 'magicattr'\n",
      "traceback: Traceback (most recent call last):\n",
      "  File \"/home/ray/anaconda3/lib/python3.11/site-packages/ray/_private/serialization.py\", line 423, in deserialize_objects\n",
      "    obj = self._deserialize_object(data, metadata, object_ref)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ray/anaconda3/lib/python3.11/site-packages/ray/_private/serialization.py\", line 280, in _deserialize_object\n",
      "    return self._deserialize_msgpack_data(data, metadata_fields)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ray/anaconda3/lib/python3.11/site-packages/ray/_private/serialization.py\", line 235, in _deserialize_msgpack_data\n",
      "    python_objects = self._deserialize_pickle5_data(pickle5_data)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ray/anaconda3/lib/python3.11/site-packages/ray/_private/serialization.py\", line 225, in _deserialize_pickle5_data\n",
      "    obj = pickle.loads(in_band)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ray/session_2024-08-27_18-52-28_256774_2706/runtime_resources/py_modules_files/_ray_pkg_4a04a2850f39c81c/dspy/__init__.py\", line 4, in <module>\n",
      "    from .predict import *\n",
      "  File \"/tmp/ray/session_2024-08-27_18-52-28_256774_2706/runtime_resources/py_modules_files/_ray_pkg_4a04a2850f39c81c/dspy/predict/__init__.py\", line 1, in <module>\n",
      "    from .aggregation import majority\n",
      "  File \"/tmp/ray/session_2024-08-27_18-52-28_256774_2706/runtime_resources/py_modules_files/_ray_pkg_4a04a2850f39c81c/dspy/predict/aggregation.py\", line 2, in <module>\n",
      "    from dspy.primitives.prediction import Completions, Prediction\n",
      "  File \"/tmp/ray/session_2024-08-27_18-52-28_256774_2706/runtime_resources/py_modules_files/_ray_pkg_4a04a2850f39c81c/dspy/primitives/__init__.py\", line 4, in <module>\n",
      "    from .program import *\n",
      "  File \"/tmp/ray/session_2024-08-27_18-52-28_256774_2706/runtime_resources/py_modules_files/_ray_pkg_4a04a2850f39c81c/dspy/primitives/program.py\", line 4, in <module>\n",
      "    import magicattr\n",
      "ModuleNotFoundError: No module named 'magicattr'\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"python/ray/_raylet.pyx\", line 2293, in ray._raylet.task_execution_handler\n",
      "  File \"python/ray/_raylet.pyx\", line 2189, in ray._raylet.execute_task_with_cancellation_handler\n",
      "  File \"python/ray/_raylet.pyx\", line 1844, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 1845, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 2083, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 1076, in ray._raylet.store_task_errors\n",
      "  File \"/home/ray/anaconda3/lib/python3.11/site-packages/ray/util/tracing/tracing_helper.py\", line 467, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ray/anaconda3/lib/python3.11/site-packages/ray/data/_internal/execution/operators/actor_pool_map_operator.py\", line 372, in __repr__\n",
      "    return f\"MapWorker({self.src_fn_name})\"\n",
      "                        ^^^^^^^^^^^^^^^^\n",
      "AttributeError: '_MapWorker' object has no attribute 'src_fn_name'\n",
      "An unexpected internal error occurred while the worker was executing a task.\u001b[32m [repeated 8x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_MapWorker pid=21814, ip=10.0.14.83)\u001b[0m No module named 'magicattr'\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=21814, ip=10.0.14.83)\u001b[0m Traceback (most recent call last):\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=21814, ip=10.0.14.83)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.11/site-packages/ray/_private/serialization.py\", line 423, in deserialize_objects\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=21814, ip=10.0.14.83)\u001b[0m     obj = self._deserialize_object(data, metadata, object_ref)\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=21814, ip=10.0.14.83)\u001b[0m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=21814, ip=10.0.14.83)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.11/site-packages/ray/_private/serialization.py\", line 280, in _deserialize_object\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=21814, ip=10.0.14.83)\u001b[0m     return self._deserialize_msgpack_data(data, metadata_fields)\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=21814, ip=10.0.14.83)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=21814, ip=10.0.14.83)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.11/site-packages/ray/_private/serialization.py\", line 235, in _deserialize_msgpack_data\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=21814, ip=10.0.14.83)\u001b[0m     python_objects = self._deserialize_pickle5_data(pickle5_data)\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=21814, ip=10.0.14.83)\u001b[0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=21814, ip=10.0.14.83)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.11/site-packages/ray/_private/serialization.py\", line 225, in _deserialize_pickle5_data\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=21814, ip=10.0.14.83)\u001b[0m     obj = pickle.loads(in_band)\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=21814, ip=10.0.14.83)\u001b[0m           ^^^^^^^^^^^^^^^^^^^^^\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=21814, ip=10.0.14.83)\u001b[0m   File \"/tmp/ray/session_2024-08-27_18-52-28_256774_2706/runtime_resources/py_modules_files/_ray_pkg_4a04a2850f39c81c/dspy/primitives/program.py\", line 4, in <module>\u001b[32m [repeated 40x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=21814, ip=10.0.14.83)\u001b[0m     from .predict import *\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=21814, ip=10.0.14.83)\u001b[0m     from .aggregation import majority\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=21814, ip=10.0.14.83)\u001b[0m     from dspy.primitives.prediction import Completions, Prediction\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=21814, ip=10.0.14.83)\u001b[0m     from .program import *\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=21814, ip=10.0.14.83)\u001b[0m     import magicattr\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=21814, ip=10.0.14.83)\u001b[0m ModuleNotFoundError: No module named 'magicattr'\u001b[32m [repeated 8x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_MapWorker pid=22766, ip=10.0.14.83)\u001b[0m [2024-08-27 19:00:45,993] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[33m(raylet)\u001b[0m Traceback (most recent call last):\n",
      "  File \"python/ray/_raylet.pyx\", line 1848, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 1882, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 985, in ray._raylet.raise_if_dependency_failed\n",
      "ray.exceptions.RaySystemError: System error: No module named 'magicattr'\n",
      "traceback: Traceback (most recent call last):\n",
      "  File \"/home/ray/anaconda3/lib/python3.11/site-packages/ray/_private/serialization.py\", line 423, in deserialize_objects\n",
      "    obj = self._deserialize_object(data, metadata, object_ref)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ray/anaconda3/lib/python3.11/site-packages/ray/_private/serialization.py\", line 280, in _deserialize_object\n",
      "    return self._deserialize_msgpack_data(data, metadata_fields)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ray/anaconda3/lib/python3.11/site-packages/ray/_private/serialization.py\", line 235, in _deserialize_msgpack_data\n",
      "    python_objects = self._deserialize_pickle5_data(pickle5_data)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ray/anaconda3/lib/python3.11/site-packages/ray/_private/serialization.py\", line 225, in _deserialize_pickle5_data\n",
      "    obj = pickle.loads(in_band)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ray/session_2024-08-27_18-52-28_256774_2706/runtime_resources/py_modules_files/_ray_pkg_4a04a2850f39c81c/dspy/__init__.py\", line 4, in <module>\n",
      "    from .predict import *\n",
      "  File \"/tmp/ray/session_2024-08-27_18-52-28_256774_2706/runtime_resources/py_modules_files/_ray_pkg_4a04a2850f39c81c/dspy/predict/__init__.py\", line 1, in <module>\n",
      "    from .aggregation import majority\n",
      "  File \"/tmp/ray/session_2024-08-27_18-52-28_256774_2706/runtime_resources/py_modules_files/_ray_pkg_4a04a2850f39c81c/dspy/predict/aggregation.py\", line 2, in <module>\n",
      "    from dspy.primitives.prediction import Completions, Prediction\n",
      "  File \"/tmp/ray/session_2024-08-27_18-52-28_256774_2706/runtime_resources/py_modules_files/_ray_pkg_4a04a2850f39c81c/dspy/primitives/__init__.py\", line 4, in <module>\n",
      "    from .program import *\n",
      "  File \"/tmp/ray/session_2024-08-27_18-52-28_256774_2706/runtime_resources/py_modules_files/_ray_pkg_4a04a2850f39c81c/dspy/primitives/program.py\", line 4, in <module>\n",
      "    import magicattr\n",
      "ModuleNotFoundError: No module named 'magicattr'\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"python/ray/_raylet.pyx\", line 2293, in ray._raylet.task_execution_handler\n",
      "  File \"python/ray/_raylet.pyx\", line 2189, in ray._raylet.execute_task_with_cancellation_handler\n",
      "  File \"python/ray/_raylet.pyx\", line 1844, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 1845, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 2083, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 1076, in ray._raylet.store_task_errors\n",
      "  File \"/home/ray/anaconda3/lib/python3.11/site-packages/ray/util/tracing/tracing_helper.py\", line 467, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ray/anaconda3/lib/python3.11/site-packages/ray/data/_internal/execution/operators/actor_pool_map_operator.py\", line 372, in __repr__\n",
      "    return f\"MapWorker({self.src_fn_name})\"\n",
      "                        ^^^^^^^^^^^^^^^^\n",
      "AttributeError: '_MapWorker' object has no attribute 'src_fn_name'\n",
      "An unexpected internal error occurred while the worker was executing a task.\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[33m(raylet)\u001b[0m A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: ffffffffffffffff6dbbd1e4ad9c99c3f23f912504000000 Worker ID: c765c2aee1eac5a0438f394d725a797e5f878821c225f608913a0c00 Node ID: c754e0939fd681cf99d21cc28faa3c642f74dba9055f314051eb4c62 Worker IP address: 10.0.14.83 Worker port: 10146 Worker PID: 22103 Worker exit type: SYSTEM_ERROR Worker exit detail: Worker exits unexpectedly. Worker exits with an exit code None. Traceback (most recent call last):\n",
      "  File \"python/ray/_raylet.pyx\", line 1848, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 1882, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 985, in ray._raylet.raise_if_dependency_failed\n",
      "ray.exceptions.RaySystemError: System error: No module named 'magicattr'\n",
      "traceback: Traceback (most recent call last):\n",
      "  File \"/home/ray/anaconda3/lib/python3.11/site-packages/ray/_private/serialization.py\", line 423, in deserialize_objects\n",
      "    obj = self._deserialize_object(data, metadata, object_ref)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ray/anaconda3/lib/python3.11/site-packages/ray/_private/serialization.py\", line 280, in _deserialize_object\n",
      "    return self._deserialize_msgpack_data(data, metadata_fields)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ray/anaconda3/lib/python3.11/site-packages/ray/_private/serialization.py\", line 235, in _deserialize_msgpack_data\n",
      "    python_objects = self._deserialize_pickle5_data(pickle5_data)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ray/anaconda3/lib/python3.11/site-packages/ray/_private/serialization.py\", line 225, in _deserialize_pickle5_data\n",
      "    obj = pickle.loads(in_band)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ray/session_2024-08-27_18-52-28_256774_2706/runtime_resources/py_modules_files/_ray_pkg_4a04a2850f39c81c/dspy/__init__.py\", line 4, in <module>\n",
      "    from .predict import *\n",
      "  File \"/tmp/ray/session_2024-08-27_18-52-28_256774_2706/runtime_resources/py_modules_files/_ray_pkg_4a04a2850f39c81c/dspy/predict/__init__.py\", line 1, in <module>\n",
      "    from .aggregation import majority\n",
      "  File \"/tmp/ray/session_2024-08-27_18-52-28_256774_2706/runtime_resources/py_modules_files/_ray_pkg_4a04a2850f39c81c/dspy/predict/aggregation.py\", line 2, in <module>\n",
      "    from dspy.primitives.prediction import Completions, Prediction\n",
      "  File \"/tmp/ray/session_2024-08-27_18-52-28_256774_2706/runtime_resources/py_modules_files/_ray_pkg_4a04a2850f39c81c/dspy/primitives/__init__.py\", line 4, in <module>\n",
      "    from .program import *\n",
      "  File \"/tmp/ray/session_2024-08-27_18-52-28_256774_2706/runtime_resources/py_modules_files/_ray_pkg_4a04a2850f39c81c/dspy/primitives/program.py\", line 4, in <module>\n",
      "    import magicattr\n",
      "ModuleNotFoundError: No module named 'magicattr'\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"python/ray/_raylet.pyx\", line 2293, in ray._raylet.task_execution_handler\n",
      "  File \"python/ray/_raylet.pyx\", line 2189, in ray._raylet.execute_task_with_cancellation_handler\n",
      "  File \"python/ray/_raylet.pyx\", line 1844, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 1845, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 2083, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 1076, in ray._raylet.store_task_errors\n",
      "  File \"/home/ray/anaconda3/lib/python3.11/site-packages/ray/util/tracing/tracing_helper.py\", line 467, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ray/anaconda3/lib/python3.11/site-packages/ray/data/_internal/execution/operators/actor_pool_map_operator.py\", line 372, in __repr__\n",
      "    return f\"MapWorker({self.src_fn_name})\"\n",
      "                        ^^^^^^^^^^^^^^^^\n",
      "AttributeError: '_MapWorker' object has no attribute 'src_fn_name'\n",
      "An unexpected internal error occurred while the worker was executing a task.\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_MapWorker pid=22790, ip=10.0.14.83)\u001b[0m No module named 'magicattr'\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=22790, ip=10.0.14.83)\u001b[0m Traceback (most recent call last):\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=22790, ip=10.0.14.83)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.11/site-packages/ray/_private/serialization.py\", line 423, in deserialize_objects\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=22790, ip=10.0.14.83)\u001b[0m     obj = self._deserialize_object(data, metadata, object_ref)\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=22790, ip=10.0.14.83)\u001b[0m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=22790, ip=10.0.14.83)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.11/site-packages/ray/_private/serialization.py\", line 280, in _deserialize_object\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=22790, ip=10.0.14.83)\u001b[0m     return self._deserialize_msgpack_data(data, metadata_fields)\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=22790, ip=10.0.14.83)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=22790, ip=10.0.14.83)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.11/site-packages/ray/_private/serialization.py\", line 235, in _deserialize_msgpack_data\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=22790, ip=10.0.14.83)\u001b[0m     python_objects = self._deserialize_pickle5_data(pickle5_data)\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=22790, ip=10.0.14.83)\u001b[0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=22790, ip=10.0.14.83)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.11/site-packages/ray/_private/serialization.py\", line 225, in _deserialize_pickle5_data\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=22790, ip=10.0.14.83)\u001b[0m     obj = pickle.loads(in_band)\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=22790, ip=10.0.14.83)\u001b[0m           ^^^^^^^^^^^^^^^^^^^^^\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=22790, ip=10.0.14.83)\u001b[0m   File \"/tmp/ray/session_2024-08-27_18-52-28_256774_2706/runtime_resources/py_modules_files/_ray_pkg_4a04a2850f39c81c/dspy/primitives/program.py\", line 4, in <module>\u001b[32m [repeated 40x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=22790, ip=10.0.14.83)\u001b[0m     from .predict import *\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=22790, ip=10.0.14.83)\u001b[0m     from .aggregation import majority\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=22790, ip=10.0.14.83)\u001b[0m     from dspy.primitives.prediction import Completions, Prediction\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=22790, ip=10.0.14.83)\u001b[0m     from .program import *\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=22790, ip=10.0.14.83)\u001b[0m     import magicattr\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=22790, ip=10.0.14.83)\u001b[0m ModuleNotFoundError: No module named 'magicattr'\u001b[32m [repeated 8x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_MapWorker pid=23752, ip=10.0.14.83)\u001b[0m [2024-08-27 19:00:51,043] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[33m(raylet)\u001b[0m Traceback (most recent call last):\n",
      "  File \"python/ray/_raylet.pyx\", line 1848, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 1882, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 985, in ray._raylet.raise_if_dependency_failed\n",
      "ray.exceptions.RaySystemError: System error: No module named 'magicattr'\n",
      "traceback: Traceback (most recent call last):\n",
      "  File \"/home/ray/anaconda3/lib/python3.11/site-packages/ray/_private/serialization.py\", line 423, in deserialize_objects\n",
      "    obj = self._deserialize_object(data, metadata, object_ref)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ray/anaconda3/lib/python3.11/site-packages/ray/_private/serialization.py\", line 280, in _deserialize_object\n",
      "    return self._deserialize_msgpack_data(data, metadata_fields)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ray/anaconda3/lib/python3.11/site-packages/ray/_private/serialization.py\", line 235, in _deserialize_msgpack_data\n",
      "    python_objects = self._deserialize_pickle5_data(pickle5_data)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ray/anaconda3/lib/python3.11/site-packages/ray/_private/serialization.py\", line 225, in _deserialize_pickle5_data\n",
      "    obj = pickle.loads(in_band)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ray/session_2024-08-27_18-52-28_256774_2706/runtime_resources/py_modules_files/_ray_pkg_4a04a2850f39c81c/dspy/__init__.py\", line 4, in <module>\n",
      "    from .predict import *\n",
      "  File \"/tmp/ray/session_2024-08-27_18-52-28_256774_2706/runtime_resources/py_modules_files/_ray_pkg_4a04a2850f39c81c/dspy/predict/__init__.py\", line 1, in <module>\n",
      "    from .aggregation import majority\n",
      "  File \"/tmp/ray/session_2024-08-27_18-52-28_256774_2706/runtime_resources/py_modules_files/_ray_pkg_4a04a2850f39c81c/dspy/predict/aggregation.py\", line 2, in <module>\n",
      "    from dspy.primitives.prediction import Completions, Prediction\n",
      "  File \"/tmp/ray/session_2024-08-27_18-52-28_256774_2706/runtime_resources/py_modules_files/_ray_pkg_4a04a2850f39c81c/dspy/primitives/__init__.py\", line 4, in <module>\n",
      "    from .program import *\n",
      "  File \"/tmp/ray/session_2024-08-27_18-52-28_256774_2706/runtime_resources/py_modules_files/_ray_pkg_4a04a2850f39c81c/dspy/primitives/program.py\", line 4, in <module>\n",
      "    import magicattr\n",
      "ModuleNotFoundError: No module named 'magicattr'\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"python/ray/_raylet.pyx\", line 2293, in ray._raylet.task_execution_handler\n",
      "  File \"python/ray/_raylet.pyx\", line 2189, in ray._raylet.execute_task_with_cancellation_handler\n",
      "  File \"python/ray/_raylet.pyx\", line 1844, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 1845, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 2083, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 1076, in ray._raylet.store_task_errors\n",
      "  File \"/home/ray/anaconda3/lib/python3.11/site-packages/ray/util/tracing/tracing_helper.py\", line 467, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ray/anaconda3/lib/python3.11/site-packages/ray/data/_internal/execution/operators/actor_pool_map_operator.py\", line 372, in __repr__\n",
      "    return f\"MapWorker({self.src_fn_name})\"\n",
      "                        ^^^^^^^^^^^^^^^^\n",
      "AttributeError: '_MapWorker' object has no attribute 'src_fn_name'\n",
      "An unexpected internal error occurred while the worker was executing a task.\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[33m(raylet)\u001b[0m A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: ffffffffffffffffee8d1497bf640fa9e50a571d04000000 Worker ID: 908ea9a93fc1e91e450385f496191b28eb4323b90a3e7e62efc99879 Node ID: c754e0939fd681cf99d21cc28faa3c642f74dba9055f314051eb4c62 Worker IP address: 10.0.14.83 Worker port: 10155 Worker PID: 23752 Worker exit type: SYSTEM_ERROR Worker exit detail: Worker exits unexpectedly. Worker exits with an exit code None. Traceback (most recent call last):\n",
      "  File \"python/ray/_raylet.pyx\", line 1848, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 1882, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 985, in ray._raylet.raise_if_dependency_failed\n",
      "ray.exceptions.RaySystemError: System error: No module named 'magicattr'\n",
      "traceback: Traceback (most recent call last):\n",
      "  File \"/home/ray/anaconda3/lib/python3.11/site-packages/ray/_private/serialization.py\", line 423, in deserialize_objects\n",
      "    obj = self._deserialize_object(data, metadata, object_ref)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ray/anaconda3/lib/python3.11/site-packages/ray/_private/serialization.py\", line 280, in _deserialize_object\n",
      "    return self._deserialize_msgpack_data(data, metadata_fields)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ray/anaconda3/lib/python3.11/site-packages/ray/_private/serialization.py\", line 235, in _deserialize_msgpack_data\n",
      "    python_objects = self._deserialize_pickle5_data(pickle5_data)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ray/anaconda3/lib/python3.11/site-packages/ray/_private/serialization.py\", line 225, in _deserialize_pickle5_data\n",
      "    obj = pickle.loads(in_band)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ray/session_2024-08-27_18-52-28_256774_2706/runtime_resources/py_modules_files/_ray_pkg_4a04a2850f39c81c/dspy/__init__.py\", line 4, in <module>\n",
      "    from .predict import *\n",
      "  File \"/tmp/ray/session_2024-08-27_18-52-28_256774_2706/runtime_resources/py_modules_files/_ray_pkg_4a04a2850f39c81c/dspy/predict/__init__.py\", line 1, in <module>\n",
      "    from .aggregation import majority\n",
      "  File \"/tmp/ray/session_2024-08-27_18-52-28_256774_2706/runtime_resources/py_modules_files/_ray_pkg_4a04a2850f39c81c/dspy/predict/aggregation.py\", line 2, in <module>\n",
      "    from dspy.primitives.prediction import Completions, Prediction\n",
      "  File \"/tmp/ray/session_2024-08-27_18-52-28_256774_2706/runtime_resources/py_modules_files/_ray_pkg_4a04a2850f39c81c/dspy/primitives/__init__.py\", line 4, in <module>\n",
      "    from .program import *\n",
      "  File \"/tmp/ray/session_2024-08-27_18-52-28_256774_2706/runtime_resources/py_modules_files/_ray_pkg_4a04a2850f39c81c/dspy/primitives/program.py\", line 4, in <module>\n",
      "    import magicattr\n",
      "ModuleNotFoundError: No module named 'magicattr'\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"python/ray/_raylet.pyx\", line 2293, in ray._raylet.task_execution_handler\n",
      "  File \"python/ray/_raylet.pyx\", line 2189, in ray._raylet.execute_task_with_cancellation_handler\n",
      "  File \"python/ray/_raylet.pyx\", line 1844, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 1845, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 2083, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 1076, in ray._raylet.store_task_errors\n",
      "  File \"/home/ray/anaconda3/lib/python3.11/site-packages/ray/util/tracing/tracing_helper.py\", line 467, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ray/anaconda3/lib/python3.11/site-packages/ray/data/_internal/execution/operators/actor_pool_map_operator.py\", line 372, in __repr__\n",
      "    return f\"MapWorker({self.src_fn_name})\"\n",
      "                        ^^^^^^^^^^^^^^^^\n",
      "AttributeError: '_MapWorker' object has no attribute 'src_fn_name'\n",
      "An unexpected internal error occurred while the worker was executing a task.\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_MapWorker pid=23784, ip=10.0.14.83)\u001b[0m No module named 'magicattr'\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=23784, ip=10.0.14.83)\u001b[0m Traceback (most recent call last):\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=23784, ip=10.0.14.83)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.11/site-packages/ray/_private/serialization.py\", line 423, in deserialize_objects\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=23784, ip=10.0.14.83)\u001b[0m     obj = self._deserialize_object(data, metadata, object_ref)\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=23784, ip=10.0.14.83)\u001b[0m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=23784, ip=10.0.14.83)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.11/site-packages/ray/_private/serialization.py\", line 280, in _deserialize_object\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=23784, ip=10.0.14.83)\u001b[0m     return self._deserialize_msgpack_data(data, metadata_fields)\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=23784, ip=10.0.14.83)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=23784, ip=10.0.14.83)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.11/site-packages/ray/_private/serialization.py\", line 235, in _deserialize_msgpack_data\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=23784, ip=10.0.14.83)\u001b[0m     python_objects = self._deserialize_pickle5_data(pickle5_data)\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=23784, ip=10.0.14.83)\u001b[0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=23784, ip=10.0.14.83)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.11/site-packages/ray/_private/serialization.py\", line 225, in _deserialize_pickle5_data\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=23784, ip=10.0.14.83)\u001b[0m     obj = pickle.loads(in_band)\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=23784, ip=10.0.14.83)\u001b[0m           ^^^^^^^^^^^^^^^^^^^^^\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=23784, ip=10.0.14.83)\u001b[0m   File \"/tmp/ray/session_2024-08-27_18-52-28_256774_2706/runtime_resources/py_modules_files/_ray_pkg_4a04a2850f39c81c/dspy/primitives/program.py\", line 4, in <module>\u001b[32m [repeated 40x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=23784, ip=10.0.14.83)\u001b[0m     from .predict import *\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=23784, ip=10.0.14.83)\u001b[0m     from .aggregation import majority\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=23784, ip=10.0.14.83)\u001b[0m     from dspy.primitives.prediction import Completions, Prediction\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=23784, ip=10.0.14.83)\u001b[0m     from .program import *\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=23784, ip=10.0.14.83)\u001b[0m     import magicattr\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=23784, ip=10.0.14.83)\u001b[0m ModuleNotFoundError: No module named 'magicattr'\u001b[32m [repeated 8x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_MapWorker pid=24827, ip=10.0.14.83)\u001b[0m [2024-08-27 19:00:57,152] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[33m(raylet)\u001b[0m Traceback (most recent call last):\n",
      "  File \"python/ray/_raylet.pyx\", line 1848, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 1882, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 985, in ray._raylet.raise_if_dependency_failed\n",
      "ray.exceptions.RaySystemError: System error: No module named 'magicattr'\n",
      "traceback: Traceback (most recent call last):\n",
      "  File \"/home/ray/anaconda3/lib/python3.11/site-packages/ray/_private/serialization.py\", line 423, in deserialize_objects\n",
      "    obj = self._deserialize_object(data, metadata, object_ref)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ray/anaconda3/lib/python3.11/site-packages/ray/_private/serialization.py\", line 280, in _deserialize_object\n",
      "    return self._deserialize_msgpack_data(data, metadata_fields)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ray/anaconda3/lib/python3.11/site-packages/ray/_private/serialization.py\", line 235, in _deserialize_msgpack_data\n",
      "    python_objects = self._deserialize_pickle5_data(pickle5_data)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ray/anaconda3/lib/python3.11/site-packages/ray/_private/serialization.py\", line 225, in _deserialize_pickle5_data\n",
      "    obj = pickle.loads(in_band)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ray/session_2024-08-27_18-52-28_256774_2706/runtime_resources/py_modules_files/_ray_pkg_4a04a2850f39c81c/dspy/__init__.py\", line 4, in <module>\n",
      "    from .predict import *\n",
      "  File \"/tmp/ray/session_2024-08-27_18-52-28_256774_2706/runtime_resources/py_modules_files/_ray_pkg_4a04a2850f39c81c/dspy/predict/__init__.py\", line 1, in <module>\n",
      "    from .aggregation import majority\n",
      "  File \"/tmp/ray/session_2024-08-27_18-52-28_256774_2706/runtime_resources/py_modules_files/_ray_pkg_4a04a2850f39c81c/dspy/predict/aggregation.py\", line 2, in <module>\n",
      "    from dspy.primitives.prediction import Completions, Prediction\n",
      "  File \"/tmp/ray/session_2024-08-27_18-52-28_256774_2706/runtime_resources/py_modules_files/_ray_pkg_4a04a2850f39c81c/dspy/primitives/__init__.py\", line 4, in <module>\n",
      "    from .program import *\n",
      "  File \"/tmp/ray/session_2024-08-27_18-52-28_256774_2706/runtime_resources/py_modules_files/_ray_pkg_4a04a2850f39c81c/dspy/primitives/program.py\", line 4, in <module>\n",
      "    import magicattr\n",
      "ModuleNotFoundError: No module named 'magicattr'\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"python/ray/_raylet.pyx\", line 2293, in ray._raylet.task_execution_handler\n",
      "  File \"python/ray/_raylet.pyx\", line 2189, in ray._raylet.execute_task_with_cancellation_handler\n",
      "  File \"python/ray/_raylet.pyx\", line 1844, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 1845, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 2083, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 1076, in ray._raylet.store_task_errors\n",
      "  File \"/home/ray/anaconda3/lib/python3.11/site-packages/ray/util/tracing/tracing_helper.py\", line 467, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ray/anaconda3/lib/python3.11/site-packages/ray/data/_internal/execution/operators/actor_pool_map_operator.py\", line 372, in __repr__\n",
      "    return f\"MapWorker({self.src_fn_name})\"\n",
      "                        ^^^^^^^^^^^^^^^^\n",
      "AttributeError: '_MapWorker' object has no attribute 'src_fn_name'\n",
      "An unexpected internal error occurred while the worker was executing a task.\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[33m(raylet)\u001b[0m A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: ffffffffffffffffee8d1497bf640fa9e50a571d04000000 Worker ID: 1d25a58a261d0ce13afd4614fd9baa789334203a05cab92f64449373 Node ID: c754e0939fd681cf99d21cc28faa3c642f74dba9055f314051eb4c62 Worker IP address: 10.0.14.83 Worker port: 10163 Worker PID: 24733 Worker exit type: SYSTEM_ERROR Worker exit detail: Worker exits unexpectedly. Worker exits with an exit code None. Traceback (most recent call last):\n",
      "  File \"python/ray/_raylet.pyx\", line 1848, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 1882, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 985, in ray._raylet.raise_if_dependency_failed\n",
      "ray.exceptions.RaySystemError: System error: No module named 'magicattr'\n",
      "traceback: Traceback (most recent call last):\n",
      "  File \"/home/ray/anaconda3/lib/python3.11/site-packages/ray/_private/serialization.py\", line 423, in deserialize_objects\n",
      "    obj = self._deserialize_object(data, metadata, object_ref)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ray/anaconda3/lib/python3.11/site-packages/ray/_private/serialization.py\", line 280, in _deserialize_object\n",
      "    return self._deserialize_msgpack_data(data, metadata_fields)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ray/anaconda3/lib/python3.11/site-packages/ray/_private/serialization.py\", line 235, in _deserialize_msgpack_data\n",
      "    python_objects = self._deserialize_pickle5_data(pickle5_data)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ray/anaconda3/lib/python3.11/site-packages/ray/_private/serialization.py\", line 225, in _deserialize_pickle5_data\n",
      "    obj = pickle.loads(in_band)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ray/session_2024-08-27_18-52-28_256774_2706/runtime_resources/py_modules_files/_ray_pkg_4a04a2850f39c81c/dspy/__init__.py\", line 4, in <module>\n",
      "    from .predict import *\n",
      "  File \"/tmp/ray/session_2024-08-27_18-52-28_256774_2706/runtime_resources/py_modules_files/_ray_pkg_4a04a2850f39c81c/dspy/predict/__init__.py\", line 1, in <module>\n",
      "    from .aggregation import majority\n",
      "  File \"/tmp/ray/session_2024-08-27_18-52-28_256774_2706/runtime_resources/py_modules_files/_ray_pkg_4a04a2850f39c81c/dspy/predict/aggregation.py\", line 2, in <module>\n",
      "    from dspy.primitives.prediction import Completions, Prediction\n",
      "  File \"/tmp/ray/session_2024-08-27_18-52-28_256774_2706/runtime_resources/py_modules_files/_ray_pkg_4a04a2850f39c81c/dspy/primitives/__init__.py\", line 4, in <module>\n",
      "    from .program import *\n",
      "  File \"/tmp/ray/session_2024-08-27_18-52-28_256774_2706/runtime_resources/py_modules_files/_ray_pkg_4a04a2850f39c81c/dspy/primitives/program.py\", line 4, in <module>\n",
      "    import magicattr\n",
      "ModuleNotFoundError: No module named 'magicattr'\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"python/ray/_raylet.pyx\", line 2293, in ray._raylet.task_execution_handler\n",
      "  File \"python/ray/_raylet.pyx\", line 2189, in ray._raylet.execute_task_with_cancellation_handler\n",
      "  File \"python/ray/_raylet.pyx\", line 1844, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 1845, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 2083, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 1076, in ray._raylet.store_task_errors\n",
      "  File \"/home/ray/anaconda3/lib/python3.11/site-packages/ray/util/tracing/tracing_helper.py\", line 467, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ray/anaconda3/lib/python3.11/site-packages/ray/data/_internal/execution/operators/actor_pool_map_operator.py\", line 372, in __repr__\n",
      "    return f\"MapWorker({self.src_fn_name})\"\n",
      "                        ^^^^^^^^^^^^^^^^\n",
      "AttributeError: '_MapWorker' object has no attribute 'src_fn_name'\n",
      "An unexpected internal error occurred while the worker was executing a task.\u001b[32m [repeated 8x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_MapWorker pid=24827, ip=10.0.14.83)\u001b[0m No module named 'magicattr'\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=24827, ip=10.0.14.83)\u001b[0m Traceback (most recent call last):\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=24827, ip=10.0.14.83)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.11/site-packages/ray/_private/serialization.py\", line 423, in deserialize_objects\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=24827, ip=10.0.14.83)\u001b[0m     obj = self._deserialize_object(data, metadata, object_ref)\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=24827, ip=10.0.14.83)\u001b[0m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=24827, ip=10.0.14.83)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.11/site-packages/ray/_private/serialization.py\", line 280, in _deserialize_object\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=24827, ip=10.0.14.83)\u001b[0m     return self._deserialize_msgpack_data(data, metadata_fields)\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=24827, ip=10.0.14.83)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=24827, ip=10.0.14.83)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.11/site-packages/ray/_private/serialization.py\", line 235, in _deserialize_msgpack_data\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=24827, ip=10.0.14.83)\u001b[0m     python_objects = self._deserialize_pickle5_data(pickle5_data)\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=24827, ip=10.0.14.83)\u001b[0m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=24827, ip=10.0.14.83)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.11/site-packages/ray/_private/serialization.py\", line 225, in _deserialize_pickle5_data\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=24827, ip=10.0.14.83)\u001b[0m     obj = pickle.loads(in_band)\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=24827, ip=10.0.14.83)\u001b[0m           ^^^^^^^^^^^^^^^^^^^^^\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=24827, ip=10.0.14.83)\u001b[0m   File \"/tmp/ray/session_2024-08-27_18-52-28_256774_2706/runtime_resources/py_modules_files/_ray_pkg_4a04a2850f39c81c/dspy/primitives/program.py\", line 4, in <module>\u001b[32m [repeated 40x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=24827, ip=10.0.14.83)\u001b[0m     from .predict import *\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=24827, ip=10.0.14.83)\u001b[0m     from .aggregation import majority\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=24827, ip=10.0.14.83)\u001b[0m     from dspy.primitives.prediction import Completions, Prediction\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=24827, ip=10.0.14.83)\u001b[0m     from .program import *\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=24827, ip=10.0.14.83)\u001b[0m     import magicattr\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=24827, ip=10.0.14.83)\u001b[0m ModuleNotFoundError: No module named 'magicattr'\u001b[32m [repeated 8x across cluster]\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[63], line 9\u001b[0m\n\u001b[1;32m      2\u001b[0m ds \u001b[38;5;241m=\u001b[39m ray\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfrom_items(devset[\u001b[38;5;241m10\u001b[39m:TEST_SIZE])\n\u001b[1;32m      3\u001b[0m ds2 \u001b[38;5;241m=\u001b[39m ds\u001b[38;5;241m.\u001b[39mmap_batches(\n\u001b[1;32m      4\u001b[0m     DSPyActor,\n\u001b[1;32m      5\u001b[0m     num_gpus\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m      6\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m      7\u001b[0m     concurrency\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m,\n\u001b[1;32m      8\u001b[0m )\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mds2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# kwargs = dict(num_threads=2, display_progress=True)\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# evaluate = Evaluate(devset=devset, metric=metric, **kwargs)\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# print(f\"Finetuned model: {bs_ft_eval}\")\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# print(f\"Finetuned model with bootstrapping: {bs_ft_bs_eval}\")\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/ray/data/dataset.py:2323\u001b[0m, in \u001b[0;36mDataset.take_batch\u001b[0;34m(self, batch_size, batch_format)\u001b[0m\n\u001b[1;32m   2320\u001b[0m limited_ds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlimit(batch_size)\n\u001b[1;32m   2322\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2323\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2324\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2325\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlimited_ds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter_batches\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2326\u001b[0m \u001b[43m                \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2327\u001b[0m \u001b[43m                \u001b[49m\u001b[43mprefetch_batches\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2328\u001b[0m \u001b[43m                \u001b[49m\u001b[43mbatch_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2329\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2330\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2331\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2332\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m   2333\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe dataset is empty.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/ray/data/iterator.py:162\u001b[0m, in \u001b[0;36mDataIterator.iter_batches.<locals>._create_iterator\u001b[0;34m()\u001b[0m\n\u001b[1;32m    157\u001b[0m time_start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter()\n\u001b[1;32m    158\u001b[0m \u001b[38;5;66;03m# Iterate through the dataset from the start each time\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;66;03m# _iterator_gen is called.\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;66;03m# This allows multiple iterations of the dataset without\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;66;03m# needing to explicitly call `iter_batches()` multiple times.\u001b[39;00m\n\u001b[0;32m--> 162\u001b[0m block_iterator, stats, blocks_owned_by_consumer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_to_block_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(\n\u001b[1;32m    165\u001b[0m     iter_batches(\n\u001b[1;32m    166\u001b[0m         block_iterator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    177\u001b[0m     )\n\u001b[1;32m    178\u001b[0m )\n\u001b[1;32m    180\u001b[0m dataset_tag \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_dataset_tag()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/ray/data/_internal/iterator/iterator_impl.py:33\u001b[0m, in \u001b[0;36mDataIteratorImpl._to_block_iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_to_block_iterator\u001b[39m(\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     27\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28mbool\u001b[39m,\n\u001b[1;32m     31\u001b[0m ]:\n\u001b[1;32m     32\u001b[0m     ds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_base_dataset\n\u001b[0;32m---> 33\u001b[0m     block_iterator, stats, executor \u001b[38;5;241m=\u001b[39m \u001b[43mds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_plan\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_to_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m     ds\u001b[38;5;241m.\u001b[39m_current_executor \u001b[38;5;241m=\u001b[39m executor\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m block_iterator, stats, \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/ray/data/exceptions.py:49\u001b[0m, in \u001b[0;36momit_traceback_stdout.<locals>.handle_trace\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhandle_trace\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 49\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     51\u001b[0m         \u001b[38;5;66;03m# Only log the full internal stack trace to stdout when configured\u001b[39;00m\n\u001b[1;32m     52\u001b[0m         \u001b[38;5;66;03m# via DataContext, or when the Ray Debugger is enabled.\u001b[39;00m\n\u001b[1;32m     53\u001b[0m         \u001b[38;5;66;03m# The full stack trace will always be emitted to the Ray Data log file.\u001b[39;00m\n\u001b[1;32m     54\u001b[0m         log_to_stdout \u001b[38;5;241m=\u001b[39m DataContext\u001b[38;5;241m.\u001b[39mget_current()\u001b[38;5;241m.\u001b[39mlog_internal_stack_trace_to_stdout\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/ray/data/_internal/plan.py:430\u001b[0m, in \u001b[0;36mExecutionPlan.execute_to_iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    428\u001b[0m gen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(block_iter)\n\u001b[1;32m    429\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 430\u001b[0m     block_iter \u001b[38;5;241m=\u001b[39m itertools\u001b[38;5;241m.\u001b[39mchain([\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m], gen)\n\u001b[1;32m    431\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    432\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/ray/data/_internal/execution/legacy_compat.py:30\u001b[0m, in \u001b[0;36mexecute_to_legacy_block_iterator\u001b[0;34m(executor, plan)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexecute_to_legacy_block_iterator\u001b[39m(\n\u001b[1;32m     26\u001b[0m     executor: Executor,\n\u001b[1;32m     27\u001b[0m     plan: ExecutionPlan,\n\u001b[1;32m     28\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[Tuple[ObjectRef[Block], BlockMetadata]]:\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;124;03m\"\"\"Same as execute_to_legacy_bundle_iterator but returning blocks and metadata.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m     bundle_iter \u001b[38;5;241m=\u001b[39m \u001b[43mexecute_to_legacy_bundle_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexecutor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplan\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m bundle \u001b[38;5;129;01min\u001b[39;00m bundle_iter:\n\u001b[1;32m     32\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m block, metadata \u001b[38;5;129;01min\u001b[39;00m bundle\u001b[38;5;241m.\u001b[39mblocks:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/ray/data/_internal/execution/legacy_compat.py:61\u001b[0m, in \u001b[0;36mexecute_to_legacy_bundle_iterator\u001b[0;34m(executor, plan, dag_rewrite)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dag_rewrite:\n\u001b[1;32m     59\u001b[0m     dag \u001b[38;5;241m=\u001b[39m dag_rewrite(dag)\n\u001b[0;32m---> 61\u001b[0m bundle_iter \u001b[38;5;241m=\u001b[39m \u001b[43mexecutor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdag\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_stats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstats\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m bundle_iter\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/ray/data/_internal/execution/streaming_executor.py:114\u001b[0m, in \u001b[0;36mStreamingExecutor.execute\u001b[0;34m(self, dag, initial_stats)\u001b[0m\n\u001b[1;32m    111\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExecution config: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_options)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;66;03m# Setup the streaming DAG topology and start the runner thread.\u001b[39;00m\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_topology, _ \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_streaming_topology\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdag\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_options\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_resource_manager \u001b[38;5;241m=\u001b[39m ResourceManager(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_topology, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_options)\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backpressure_policies \u001b[38;5;241m=\u001b[39m get_backpressure_policies(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_topology)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/ray/data/_internal/execution/streaming_executor_state.py:353\u001b[0m, in \u001b[0;36mbuild_streaming_topology\u001b[0;34m(dag, options)\u001b[0m\n\u001b[1;32m    350\u001b[0m     op\u001b[38;5;241m.\u001b[39mstart(options)\n\u001b[1;32m    351\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op_state\n\u001b[0;32m--> 353\u001b[0m \u001b[43msetup_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdag\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[38;5;66;03m# Create the progress bars starting from the first operator to run.\u001b[39;00m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;66;03m# Note that the topology dict is in topological sort order. Index zero is reserved\u001b[39;00m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;66;03m# for global progress information.\u001b[39;00m\n\u001b[1;32m    358\u001b[0m i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/ray/data/_internal/execution/streaming_executor_state.py:344\u001b[0m, in \u001b[0;36mbuild_streaming_topology.<locals>.setup_state\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m    342\u001b[0m inqueues \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, parent \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(op\u001b[38;5;241m.\u001b[39minput_dependencies):\n\u001b[0;32m--> 344\u001b[0m     parent_state \u001b[38;5;241m=\u001b[39m \u001b[43msetup_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    345\u001b[0m     inqueues\u001b[38;5;241m.\u001b[39mappend(parent_state\u001b[38;5;241m.\u001b[39moutqueue)\n\u001b[1;32m    347\u001b[0m \u001b[38;5;66;03m# Create state.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/ray/data/_internal/execution/streaming_executor_state.py:350\u001b[0m, in \u001b[0;36mbuild_streaming_topology.<locals>.setup_state\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m    348\u001b[0m op_state \u001b[38;5;241m=\u001b[39m OpState(op, inqueues)\n\u001b[1;32m    349\u001b[0m topology[op] \u001b[38;5;241m=\u001b[39m op_state\n\u001b[0;32m--> 350\u001b[0m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op_state\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/ray/data/_internal/execution/operators/actor_pool_map_operator.py:135\u001b[0m, in \u001b[0;36mActorPoolMapOperator.start\u001b[0;34m(self, options)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    134\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m DataContext\u001b[38;5;241m.\u001b[39mget_current()\u001b[38;5;241m.\u001b[39mwait_for_min_actors_s\n\u001b[0;32m--> 135\u001b[0m     \u001b[43mray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrefs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ray\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mGetTimeoutError:\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ray\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mGetTimeoutError(\n\u001b[1;32m    138\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTimed out while starting actors. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    139\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis may mean that the cluster does not have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    140\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menough resources for the requested actor pool.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    141\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/ray/_private/auto_init_hook.py:21\u001b[0m, in \u001b[0;36mwrap_auto_init.<locals>.auto_init_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(fn)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mauto_init_wrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     20\u001b[0m     auto_init_ray()\n\u001b[0;32m---> 21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/ray/_private/client_mode_hook.py:103\u001b[0m, in \u001b[0;36mclient_mode_hook.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minit\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m is_client_mode_enabled_by_default:\n\u001b[1;32m    102\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(ray, func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/ray/_private/worker.py:2656\u001b[0m, in \u001b[0;36mget\u001b[0;34m(object_refs, timeout)\u001b[0m\n\u001b[1;32m   2650\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2651\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid type of object refs, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(object_refs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, is given. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2652\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobject_refs\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m must either be an ObjectRef or a list of ObjectRefs. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2653\u001b[0m     )\n\u001b[1;32m   2655\u001b[0m \u001b[38;5;66;03m# TODO(ujvl): Consider how to allow user to retrieve the ready objects.\u001b[39;00m\n\u001b[0;32m-> 2656\u001b[0m values, debugger_breakpoint \u001b[38;5;241m=\u001b[39m \u001b[43mworker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_objects\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobject_refs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2657\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(values):\n\u001b[1;32m   2658\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, RayError):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/ray/_private/worker.py:848\u001b[0m, in \u001b[0;36mWorker.get_objects\u001b[0;34m(self, object_refs, timeout, return_exceptions)\u001b[0m\n\u001b[1;32m    842\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    843\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempting to call `get` on the value \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobject_ref\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    844\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhich is not an ray.ObjectRef.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    845\u001b[0m         )\n\u001b[1;32m    847\u001b[0m timeout_ms \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(timeout \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 848\u001b[0m data_metadata_pairs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcore_worker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_objects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    849\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobject_refs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    850\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_task_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    851\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout_ms\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    852\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    853\u001b[0m debugger_breakpoint \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    854\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data, metadata \u001b[38;5;129;01min\u001b[39;00m data_metadata_pairs:\n",
      "File \u001b[0;32mpython/ray/_raylet.pyx:3508\u001b[0m, in \u001b[0;36mray._raylet.CoreWorker.get_objects\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpython/ray/_raylet.pyx:574\u001b[0m, in \u001b[0;36mray._raylet.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "TEST_SIZE = 300\n",
    "ds = ray.data.from_items(devset[10:TEST_SIZE])\n",
    "ds2 = ds.map_batches(\n",
    "    DSPyActor,\n",
    "    num_gpus=1,\n",
    "    batch_size=1,\n",
    "    concurrency=8,\n",
    ")\n",
    "print(ds2.take_batch(10))\n",
    "# kwargs = dict(num_threads=2, display_progress=True)\n",
    "# evaluate = Evaluate(devset=devset, metric=metric, **kwargs)\n",
    "\n",
    "# baseline_eval = evaluate(BasicMH(**program_params), devset=devset[:TEST_SIZE])\n",
    "# bs_eval = evaluate(basicmh_bs, devset=devset[:TEST_SIZE])\n",
    "# bs_ft_eval = evaluate(basicmh_bs_ft, devset=devset[:TEST_SIZE])\n",
    "# bs_ft_bs_eval = evaluate(basicmh_bs_ft_bs, devset=devset[:TEST_SIZE])\n",
    "\n",
    "# print(f\"Results for HotPotQA finetuning gpt-4o-mini with rejection sampling N={samples} and up to 1 attempts for each example with one model for all predictors. Tested on first {TEST_SIZE} of devset.\")\n",
    "# print(f\"Non-finetuned model: {baseline_eval}\")\n",
    "# print(f\"Non-finetuned bootstrapped model: {bs_eval}\")\n",
    "# print(f\"Finetuned model: {bs_ft_eval}\")\n",
    "# print(f\"Finetuned model with bootstrapping: {bs_ft_bs_eval}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WORKING HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
